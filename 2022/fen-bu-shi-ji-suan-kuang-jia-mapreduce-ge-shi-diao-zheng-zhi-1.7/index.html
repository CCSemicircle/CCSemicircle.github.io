<!DOCTYPE HTML>
<html lang="zh-Hans">


<head>
    <meta charset="utf-8">
    <meta name="keywords" content="分布式计算框架MapReduce, 软件工程,前端,NLP">
    <meta name="description" content="1 MapReduce概述1.1 MapReduce定义
MapReduce是一个分布式运算程序的编程框架，是用户开发“基于Hadoop的数据分析应用”的核心框架。
MapReducet核心功能是将用户编写的业务逻辑代码和自带默认组件整合成">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=no">
    <meta name="renderer" content="webkit|ie-stand|ie-comp">
    <meta name="mobile-web-app-capable" content="yes">
    <meta name="format-detection" content="telephone=no">
    <meta name="apple-mobile-web-app-capable" content="yes">
    <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
    <meta name="referrer" content="no-referrer-when-downgrade">
    <!-- Global site tag (gtag.js) - Google Analytics -->


    <title>分布式计算框架MapReduce | fdChen的掉发收集箱</title>
    <link rel="icon" type="image/png" href="/favicon.png">

    <link rel="stylesheet" type="text/css" href="/libs/awesome/css/all.min.css">
    <link rel="stylesheet" type="text/css" href="/libs/materialize/materialize.min.css">
    <link rel="stylesheet" type="text/css" href="/libs/aos/aos.css">
    <link rel="stylesheet" type="text/css" href="/libs/animate/animate.min.css">
    <link rel="stylesheet" type="text/css" href="/libs/lightGallery/css/lightgallery.min.css">
    <link rel="stylesheet" type="text/css" href="/css/matery.css">
    <link rel="stylesheet" type="text/css" href="/css/my.css">

    <script src="/libs/jquery/jquery-3.6.0.min.js"></script>

<meta name="generator" content="Hexo 6.1.0"></head>




<body>
    <header class="navbar-fixed">
    <nav id="headNav" class="bg-color nav-transparent">
        <div id="navContainer" class="nav-wrapper container">
            <div class="brand-logo">
                <a href="/" class="waves-effect waves-light">
                    
                    <img src="/medias/logo.png" class="logo-img" alt="LOGO">
                    
                    <span class="logo-span">fdChen的掉发收集箱</span>
                </a>
            </div>
            

<a href="#" data-target="mobile-nav" class="sidenav-trigger button-collapse"><i class="fas fa-bars"></i></a>
<ul class="right nav-menu">
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/" class="waves-effect waves-light">
      
      <i class="fas fa-home" style="zoom: 0.6;"></i>
      
      <span>Index</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/tags" class="waves-effect waves-light">
      
      <i class="fas fa-tags" style="zoom: 0.6;"></i>
      
      <span>Tags</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/categories" class="waves-effect waves-light">
      
      <i class="fas fa-bookmark" style="zoom: 0.6;"></i>
      
      <span>Categories</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/archives" class="waves-effect waves-light">
      
      <i class="fas fa-archive" style="zoom: 0.6;"></i>
      
      <span>Archives</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/about" class="waves-effect waves-light">
      
      <i class="fas fa-user-circle" style="zoom: 0.6;"></i>
      
      <span>About</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/contact" class="waves-effect waves-light">
      
      <i class="fas fa-comments" style="zoom: 0.6;"></i>
      
      <span>Contact</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/friends" class="waves-effect waves-light">
      
      <i class="fas fa-address-book" style="zoom: 0.6;"></i>
      
      <span>Friends</span>
    </a>
    
  </li>
  
  <li>
    <a href="#searchModal" class="modal-trigger waves-effect waves-light">
      <i id="searchIcon" class="fas fa-search" title="Search" style="zoom: 0.85;"></i>
    </a>
  </li>
</ul>


<div id="mobile-nav" class="side-nav sidenav">

    <div class="mobile-head bg-color">
        
        <img src="/medias/logo.png" class="logo-img circle responsive-img">
        
        <div class="logo-name">fdChen的掉发收集箱</div>
        <div class="logo-desc">
            
            一些想到什么写什么的记录
            
        </div>
    </div>

    <ul class="menu-list mobile-menu-list">
        
        <li class="m-nav-item">
	  
		<a href="/" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-home"></i>
			
			Index
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/tags" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-tags"></i>
			
			Tags
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/categories" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-bookmark"></i>
			
			Categories
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/archives" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-archive"></i>
			
			Archives
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/about" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-user-circle"></i>
			
			About
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/contact" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-comments"></i>
			
			Contact
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/friends" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-address-book"></i>
			
			Friends
		</a>
          
        </li>
        
        
        <li><div class="divider"></div></li>
        <li>
            <a href="https://github.com/CCSemicircle" class="waves-effect waves-light" target="_blank">
                <i class="fab fa-github-square fa-fw"></i>Fork Me
            </a>
        </li>
        
    </ul>
</div>


        </div>

        
            <style>
    .nav-transparent .github-corner {
        display: none !important;
    }

    .github-corner {
        position: absolute;
        z-index: 10;
        top: 0;
        right: 0;
        border: 0;
        transform: scale(1.1);
    }

    .github-corner svg {
        color: #0f9d58;
        fill: #fff;
        height: 64px;
        width: 64px;
    }

    .github-corner:hover .octo-arm {
        animation: a 0.56s ease-in-out;
    }

    .github-corner .octo-arm {
        animation: none;
    }

    @keyframes a {
        0%,
        to {
            transform: rotate(0);
        }
        20%,
        60% {
            transform: rotate(-25deg);
        }
        40%,
        80% {
            transform: rotate(10deg);
        }
    }
</style>

<a href="https://github.com/CCSemicircle" class="github-corner tooltipped hide-on-med-and-down" target="_blank"
   data-tooltip="Fork Me" data-position="left" data-delay="50">
    <svg viewBox="0 0 250 250" aria-hidden="true">
        <path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path>
        <path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2"
              fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"></path>
        <path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z"
              fill="currentColor" class="octo-body"></path>
    </svg>
</a>
        
    </nav>

</header>

    



<div class="bg-cover pd-header post-cover" style="background-image: url('/medias/featureimages/14.jpg')">
    <div class="container" style="right: 0px;left: 0px;">
        <div class="row">
            <div class="col s12 m12 l12">
                <div class="brand">
                    <h1 class="description center-align post-title">分布式计算框架MapReduce</h1>
                </div>
            </div>
        </div>
    </div>
</div>




<main class="post-container content">

    
    <link rel="stylesheet" href="/libs/tocbot/tocbot.css">
<style>
    #articleContent h1::before,
    #articleContent h2::before,
    #articleContent h3::before,
    #articleContent h4::before,
    #articleContent h5::before,
    #articleContent h6::before {
        display: block;
        content: " ";
        height: 100px;
        margin-top: -100px;
        visibility: hidden;
    }

    #articleContent :focus {
        outline: none;
    }

    .toc-fixed {
        position: fixed;
        top: 64px;
    }

    .toc-widget {
        width: 345px;
        padding-left: 20px;
    }

    .toc-widget .toc-title {
        padding: 35px 0 15px 17px;
        font-size: 1.5rem;
        font-weight: bold;
        line-height: 1.5rem;
    }

    .toc-widget ol {
        padding: 0;
        list-style: none;
    }

    #toc-content {
        padding-bottom: 30px;
        overflow: auto;
    }

    #toc-content ol {
        padding-left: 10px;
    }

    #toc-content ol li {
        padding-left: 10px;
    }

    #toc-content .toc-link:hover {
        color: #42b983;
        font-weight: 700;
        text-decoration: underline;
    }

    #toc-content .toc-link::before {
        background-color: transparent;
        max-height: 25px;

        position: absolute;
        right: 23.5vw;
        display: block;
    }

    #toc-content .is-active-link {
        color: #42b983;
    }

    #floating-toc-btn {
        position: fixed;
        right: 15px;
        bottom: 76px;
        padding-top: 15px;
        margin-bottom: 0;
        z-index: 998;
    }

    #floating-toc-btn .btn-floating {
        width: 48px;
        height: 48px;
    }

    #floating-toc-btn .btn-floating i {
        line-height: 48px;
        font-size: 1.4rem;
    }
</style>
<div class="row">
    <div id="main-content" class="col s12 m12 l9">
        <!-- 文章内容详情 -->
<div id="artDetail">
    <div class="card">
        <div class="card-content article-info">
            <div class="row tag-cate">
                <div class="col s7">
                    
                    <div class="article-tag">
                        
                            <a href="/tags/Hadoop/">
                                <span class="chip bg-color">Hadoop</span>
                            </a>
                        
                            <a href="/tags/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/">
                                <span class="chip bg-color">学习笔记</span>
                            </a>
                        
                            <a href="/tags/%E6%95%99%E7%A8%8B/">
                                <span class="chip bg-color">教程</span>
                            </a>
                        
                            <a href="/tags/MapReduce/">
                                <span class="chip bg-color">MapReduce</span>
                            </a>
                        
                    </div>
                    
                </div>
                <div class="col s5 right-align">
                    
                    <div class="post-cate">
                        <i class="fas fa-bookmark fa-fw icon-category"></i>
                        
                            <a href="/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90/" class="post-category">
                                大数据分析
                            </a>
                        
                            <a href="/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90/Hadoop%E5%B7%A5%E5%85%B7%E4%BD%BF%E7%94%A8%E6%95%99%E7%A8%8B/" class="post-category">
                                Hadoop工具使用教程
                            </a>
                        
                    </div>
                    
                </div>
            </div>

            <div class="post-info">
                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-minus fa-fw"></i>Publish Date:&nbsp;&nbsp;
                    2022-03-16
                </div>
                

                

                
                <div class="info-break-policy">
                    <i class="far fa-file-word fa-fw"></i>Word Count:&nbsp;&nbsp;
                    14.9k
                </div>
                

                
                <div class="info-break-policy">
                    <i class="far fa-clock fa-fw"></i>Read Times:&nbsp;&nbsp;
                    66 Min
                </div>
                

                
                    <div id="busuanzi_container_page_pv" class="info-break-policy">
                        <i class="far fa-eye fa-fw"></i>Read Count:&nbsp;&nbsp;
                        <span id="busuanzi_value_page_pv"></span>
                    </div>
				
            </div>
        </div>
        <hr class="clearfix">

        

        

        <div class="card-content article-card-content">
            <div id="articleContent">
                <h1 id="1-MapReduce概述"><a href="#1-MapReduce概述" class="headerlink" title="1 MapReduce概述"></a>1 MapReduce概述</h1><h2 id="1-1-MapReduce定义"><a href="#1-1-MapReduce定义" class="headerlink" title="1.1 MapReduce定义"></a>1.1 MapReduce定义</h2><ol>
<li>MapReduce是一个<strong>分布式运算程序的编程框架</strong>，是用户开发“基于Hadoop的<br>数据分析应用”的核心框架。</li>
<li>MapReducet核心功能是<strong>将用户编写的业务逻辑代码和自带默认组件整合成一个<br>完整的分布式运算程序，并发运行在一个Hadoop集群上。</strong></li>
</ol>
<h2 id="1-2-MapReduce优缺点"><a href="#1-2-MapReduce优缺点" class="headerlink" title="1.2 MapReduce优缺点"></a>1.2 MapReduce优缺点</h2><h3 id="1-2-1-优点"><a href="#1-2-1-优点" class="headerlink" title="1.2.1 优点"></a>1.2.1 优点</h3><ol>
<li><p>MapReduce易于编程<br>它简单的实现一些接口，就可以完成一个分布式程序，这个分布式程序可以分布到大量廉价的PC机器上运行。也就是说你写一个分布式程序，跟写一个简单的串行程序是一模一样的。就是因为这个特点使得MapReduce编程变得非常流行。</p>
</li>
<li><p>良好的扩展性<br>当尔的计算资源不能得到满足的时候，你可以通过简单的增加机器来扩展它的计算能力。</p>
</li>
<li><p>高容错性<br>MapReduce设计的初衷就是使程序能够部署在廉价的PC机器上，这就要求它具有很高的容错性。比如其中一台机器挂了，它可以把上面的计算任务转移到另外一个节点上运行，不至于这个任务运行失败，而且这个过程不需要人工参与，而完全是由Hadoop内部完成的。</p>
</li>
<li><p>适合PB级以上海量数据的离线处理<br>可以实现上千台服务器集群并发工作，提供好据处理能力。</p>
</li>
</ol>
<h3 id="1-2-2-缺点"><a href="#1-2-2-缺点" class="headerlink" title="1.2.2 缺点"></a>1.2.2 缺点</h3><ol>
<li>不擅长实时计算<br>MapReduce无法像MySQL一样，在毫秒或者秒级内返回结果。</li>
<li>不擅长流式计算<br>流式计算的输入数据是动态的，而MapReduce的输入数据集是静态的，不能动态变化。这是因为MapReduce自身的设计特点决定了数据源必须是静态的。</li>
<li>不擅长DAG（有向图）计算<br>多个应用程序存在依赖关系，后一个应用程序的输入为前一个的输出。在这种情兄下，MapReduce并不是不能做，而是使用后，每个MapReducef作业的输出结果都会写入到磁盘，会造成大量的磁盘I&#x2F;O，导致性能非常的低下。</li>
</ol>
<span id="more"></span>

<h2 id="1-3-MapReduce核心思想"><a href="#1-3-MapReduce核心思想" class="headerlink" title="1.3 MapReduce核心思想"></a>1.3 MapReduce核心思想</h2><p><img src="http://img.fdchen.host/MapReduce%E6%A0%B8%E5%BF%83%E7%BC%96%E7%A8%8B%E6%80%9D%E6%83%B3.png" alt="MapReduce核心编程思想"></p>
<center>图1.1 MapReduce核心编程思想</center>

<ul>
<li>分布式的运算程序往往需要分成至少2个阶段。</li>
</ul>
<ol>
<li>第一个阶段的MapTask并发实例，完全并行运行，互不相干。</li>
<li>第二个阶段的ReduceTask并发实例互不相干，但是他们的数据依赖于上一个阶段的所有MapTask并发实例的输出。</li>
<li>MapReduce编程模型<strong>只能包含一个Map阶段和一个Reduce阶段</strong>，如果用户的业务逻辑非常复杂，那就只能<strong>多个MapReduce程序，串行运行</strong>。</li>
</ol>
<h2 id="1-4-MapReduce进程"><a href="#1-4-MapReduce进程" class="headerlink" title="1.4 MapReduce进程"></a>1.4 MapReduce进程</h2><ul>
<li>一个完整的MapReduce程序分布式运行时有三类实例进程：</li>
</ul>
<ol>
<li><strong>MrAppMaster：</strong>负责整个程序的过程调度及状态协调。</li>
<li><strong>MapTask：</strong>负责Map阶段的整个数据处理流程。</li>
<li><strong>ReduceTask：</strong>负责Reduce阶段的整个数据处理流程。</li>
</ol>
<h2 id="1-5-官方WordCount源码"><a href="#1-5-官方WordCount源码" class="headerlink" title="1.5 官方WordCount源码"></a>1.5 官方WordCount源码</h2><p>采用反编译工具反编译源码，发现WordCount案例有Map类、Reduce类和驱动类。且数据的类型是Hadoop自身封装的序列化类型。</p>
<p><strong>Tip：</strong></p>
<ul>
<li><strong>序列化 (Serialization)是将对象的状态信息转换为可以存储或传输的形式的过程。在序列化期间，对象将其当前状态写入到临时或持久性存储区。以后，可以通过从存储区中读取或反序列化对象的状态，重新创建该对象。详情见第2章。</strong></li>
</ul>
<h2 id="1-6-常用数据序列化类型"><a href="#1-6-常用数据序列化类型" class="headerlink" title="1.6 常用数据序列化类型"></a>1.6 常用数据序列化类型</h2><center>表1.1 常用的数据类型对应的Hadoop数据序列化类型</center>

<table>
<thead>
<tr>
<th><strong>Java类型</strong></th>
<th><strong>Hadoop Writable类型</strong></th>
</tr>
</thead>
<tbody><tr>
<td>boolean</td>
<td>BooleanWritable</td>
</tr>
<tr>
<td>byte</td>
<td>ByteWritable</td>
</tr>
<tr>
<td>int</td>
<td>IntWritable</td>
</tr>
<tr>
<td>float</td>
<td>FloatWritable</td>
</tr>
<tr>
<td>long</td>
<td>LongWritable</td>
</tr>
<tr>
<td>double</td>
<td>DoubleWritable</td>
</tr>
<tr>
<td>String</td>
<td>Text</td>
</tr>
<tr>
<td>map</td>
<td>MapWritable</td>
</tr>
<tr>
<td>array</td>
<td>ArrayWritable</td>
</tr>
</tbody></table>
<p><strong>Tip：有关IntWritable等序列化类型使用详见博客<a target="_blank" rel="noopener" href="https://blog.csdn.net/ghuilee/article/details/45705169">《IntWritable详解》</a></strong></p>
<h2 id="1-7-MapReduce编程规范"><a href="#1-7-MapReduce编程规范" class="headerlink" title="1.7 MapReduce编程规范"></a>1.7 MapReduce编程规范</h2><ul>
<li>用户编写的程序分成三个部分：Mapper、Reducer和Driver。</li>
</ul>
<ol>
<li><strong>Mapper阶段</strong></li>
</ol>
<p>（1）用户自定义的Mapper要继承自己的父类<br>（2）Mapper的输入数据是KV(Key-Value)对的形式(KV的类型可自定义)<br>（3）Mapper中的业务逻辑写在map()方法中<br>（4）Mapper的输出数据是KV(Key-Value)对的形式(KV的类型可自定义)<br>（5）map()方法（MapTask进程）对<strong>每一个初始输入数据的&lt;K,V&gt;调用一次</strong></p>
<ol start="2">
<li><strong>Reduce阶段</strong></li>
</ol>
<p>（1）用户自定义的Reducer要继承自己的父类<br>（2）Reducer的输入数据类型对应Mapper的输出数据类型，也是KV对<br>（3）Reducer的业务逻辑写在reduce()方法中<br>（4）ReduceTask进程对<strong>Mapper阶段输出的每一组相同k的&lt;k,v&gt;组调用一次</strong>reduce()方法</p>
<ol start="3">
<li><strong>Driver阶段</strong></li>
</ol>
<p>相当于YARN集群的客户端，用于提交我们整个程序到YARN集群，提交的是封装了MapReduce程序相关运行参数job对象。</p>
<h2 id="1-8-WordCount案例实操"><a href="#1-8-WordCount案例实操" class="headerlink" title="1.8 WordCount案例实操"></a>1.8 WordCount案例实操</h2><ol>
<li><strong>需求</strong></li>
</ol>
<p>在给定的文本文件中统计输出每一个单词出现的总次数</p>
<p>（1）输入数据为文本文件：<a target="_blank" rel="noopener" href="http://img.fdchen.host/hello.txt">hello.txt</a><br>（2）期望输出数据：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">atguigu	<span class="number">2</span></span><br><span class="line">banzhang	<span class="number">1</span></span><br><span class="line">cls	<span class="number">2</span></span><br><span class="line">hadoop	<span class="number">1</span></span><br><span class="line">jiao	<span class="number">1</span></span><br><span class="line">ss	<span class="number">2</span></span><br><span class="line">xue	<span class="number">1</span></span><br></pre></td></tr></table></figure>

<ol start="2">
<li><strong>需求分析</strong></li>
</ol>
<p>按照MapReduce编程规范，分别编写Mapper，Reducer，Driver，如图1.2：<br><img src="http://img.fdchen.host/WordCount%E6%A1%88%E4%BE%8B%E9%9C%80%E6%B1%82%E5%88%86%E6%9E%90.png" alt="WordCount案例需求分析"></p>
<center>图1.2 WordCount案例需求分析</center>

<ol start="3">
<li><strong>环境准备</strong></li>
</ol>
<p>（1）创建maven工程</p>
<p>（2）在pom.xml文件中添加如下依赖</p>
<figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">dependencies</span>&gt;</span></span><br><span class="line">		<span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">			<span class="tag">&lt;<span class="name">groupId</span>&gt;</span>junit<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">			<span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>junit<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">			<span class="tag">&lt;<span class="name">version</span>&gt;</span>RELEASE<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line">		<span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br><span class="line">		<span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">			<span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.apache.logging.log4j<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">			<span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>log4j-core<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">			<span class="tag">&lt;<span class="name">version</span>&gt;</span>2.8.2<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line">		<span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br><span class="line">		<span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">			<span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.apache.hadoop<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">			<span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>hadoop-common<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">			<span class="tag">&lt;<span class="name">version</span>&gt;</span>2.7.2<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line">		<span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br><span class="line">		<span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">			<span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.apache.hadoop<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">			<span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>hadoop-client<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">			<span class="tag">&lt;<span class="name">version</span>&gt;</span>2.7.2<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line">		<span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br><span class="line">		<span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">			<span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.apache.hadoop<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">			<span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>hadoop-hdfs<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">			<span class="tag">&lt;<span class="name">version</span>&gt;</span>2.7.2<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line">		<span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">dependencies</span>&gt;</span></span><br></pre></td></tr></table></figure>

<p>（2）在项目的src&#x2F;main&#x2F;resources目录下，新建一个文件，命名为“log4j.properties”，在文件中填入如下内容：</p>
<figure class="highlight properties"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">log4j.rootLogger</span>=<span class="string">INFO, stdout</span></span><br><span class="line"><span class="attr">log4j.appender.stdout</span>=<span class="string">org.apache.log4j.ConsoleAppender</span></span><br><span class="line"><span class="attr">log4j.appender.stdout.layout</span>=<span class="string">org.apache.log4j.PatternLayout</span></span><br><span class="line"><span class="attr">log4j.appender.stdout.layout.ConversionPattern</span>=<span class="string">%d %p [%c] - %m%n</span></span><br><span class="line"><span class="attr">log4j.appender.logfile</span>=<span class="string">org.apache.log4j.FileAppender</span></span><br><span class="line"><span class="attr">log4j.appender.logfile.File</span>=<span class="string">target/spring.log</span></span><br><span class="line"><span class="attr">log4j.appender.logfile.layout</span>=<span class="string">org.apache.log4j.PatternLayout</span></span><br><span class="line"><span class="attr">log4j.appender.logfile.layout.ConversionPattern</span>=<span class="string">%d %p [%c] - %m%n</span></span><br></pre></td></tr></table></figure>

<ol start="4">
<li><strong>编写程序</strong></li>
</ol>
<p>（1）编写Mapper类</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> java.io.IOException;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> javax.sound.sampled.Line;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.io.IntWritable;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.io.LongWritable;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.io.Text;  </span><br><span class="line"><span class="comment">// 注意导入正确jar包：xxx.io.Text</span></span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.mapreduce.Mapper;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> com.sun.tools.classfile.StackMapTable_attribute.verification_type_info;</span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * Map阶段</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@param</span> </span></span><br><span class="line"><span class="comment"> * KEYIN 输入数据的key</span></span><br><span class="line"><span class="comment"> * VALUEIN 输入数据的value</span></span><br><span class="line"><span class="comment"> * KEYOUT 输出数据的key的类型</span></span><br><span class="line"><span class="comment"> * VALUEOUT 输出数据的value类型</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">WordCountMapper</span> <span class="keyword">extends</span> <span class="title class_">Mapper</span>&lt;LongWritable, Text, Text, IntWritable&gt;&#123;</span><br><span class="line">	<span class="type">Text</span> <span class="variable">k</span> <span class="operator">=</span><span class="keyword">new</span> <span class="title class_">Text</span>();</span><br><span class="line">	<span class="type">IntWritable</span>  <span class="variable">v</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">IntWritable</span>(<span class="number">1</span>);</span><br><span class="line">	</span><br><span class="line">	<span class="meta">@Override</span></span><br><span class="line">	<span class="keyword">protected</span> <span class="keyword">void</span> <span class="title function_">map</span><span class="params">(LongWritable key, Text value, Context context)</span> <span class="keyword">throws</span> IOException, InterruptedException&#123;</span><br><span class="line">		<span class="comment">// 文本内容为： atguigu atguigu</span></span><br><span class="line">		</span><br><span class="line">		<span class="comment">// 1  获取1行</span></span><br><span class="line">		<span class="type">String</span> <span class="variable">line</span> <span class="operator">=</span>value.toString();</span><br><span class="line">		</span><br><span class="line">		<span class="comment">// 2 切割单词</span></span><br><span class="line">        <span class="comment">// 注意切割符号要正确，不然结果会出现偏差</span></span><br><span class="line">		String[] words = line.split(<span class="string">&quot; &quot;</span>); </span><br><span class="line">		</span><br><span class="line">		<span class="comment">// 3 循环写出</span></span><br><span class="line">		<span class="keyword">for</span>(String word:words) &#123;</span><br><span class="line">			</span><br><span class="line">			<span class="comment">// set()将word设置为Text的值</span></span><br><span class="line">			k.set(word);</span><br><span class="line">			</span><br><span class="line">			context.write(k, v);</span><br><span class="line">			</span><br><span class="line">		&#125;</span><br><span class="line">	&#125;</span><br><span class="line">	</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>（2）编写Redcuer类</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> java.io.IOException;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.io.IntWritable;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.io.Text;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.mapreduce.Reducer;  </span><br><span class="line"><span class="comment">// 注意导入正确的jar包：xxx.mapreduce.Reducer</span></span><br><span class="line"></span><br><span class="line"><span class="comment">// KEYIN VALUEIN map阶段输出的key和value</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">WordCountReducer</span> <span class="keyword">extends</span> <span class="title class_">Reducer</span>&lt;Text, IntWritable, Text, IntWritable&gt;&#123;</span><br><span class="line">	</span><br><span class="line">	<span class="type">IntWritable</span>  <span class="variable">v</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">IntWritable</span>();</span><br><span class="line">	</span><br><span class="line">	<span class="comment">// Iterable&lt;IntWritable&gt;为类型为IntWritable的迭代器</span></span><br><span class="line">	<span class="meta">@Override</span></span><br><span class="line">	<span class="keyword">protected</span> <span class="keyword">void</span> <span class="title function_">reduce</span><span class="params">(Text key, Iterable&lt;IntWritable&gt; values, Context context)</span> <span class="keyword">throws</span> IOException, InterruptedException&#123;</span><br><span class="line">		<span class="comment">// 输入数据为： &lt;atguigu,1&gt; &lt;atguigu,1&gt;</span></span><br><span class="line">		<span class="type">int</span> sum=<span class="number">0</span>;</span><br><span class="line">		</span><br><span class="line">		<span class="comment">// 1 累加求和</span></span><br><span class="line">		<span class="keyword">for</span>(IntWritable value:values) &#123;</span><br><span class="line">			sum += value.get();</span><br><span class="line">		&#125;</span><br><span class="line">		</span><br><span class="line">		v.set(sum);</span><br><span class="line">		</span><br><span class="line">		<span class="comment">// 2 写出atguigu 2</span></span><br><span class="line">		context.write(key, v);</span><br><span class="line">	&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>（3）编写Driver驱动类</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> java.io.IOException;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.conf.Configuration;  </span><br><span class="line"><span class="comment">// 注意导入正确jar包：xxx.conf.Configuration</span></span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.fs.Path;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.io.IntWritable;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.io.Text;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.mapreduce.Job;  </span><br><span class="line"><span class="comment">// 注意导入正确jar包：xxx.mapreduce.Job</span></span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.mapreduce.lib.input.FileInputFormat; </span><br><span class="line"><span class="comment">// 注意导入正确jar包：xxx.lib.input.FileInputFormat</span></span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.mapreduce.lib.output.FileOutputFormat;</span><br><span class="line"><span class="comment">// 注意导入正确jar包：xxx.lib.output.FileOutputFormat</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">WordCountDriver</span> &#123;</span><br><span class="line">	<span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title function_">main</span><span class="params">(String args[])</span> <span class="keyword">throws</span> IOException, ClassNotFoundException, InterruptedException &#123;</span><br><span class="line">		</span><br><span class="line">		Configuration conf= <span class="keyword">new</span> <span class="title class_">Configuration</span>();</span><br><span class="line">		<span class="comment">// 1 获取job对象</span></span><br><span class="line">		<span class="type">Job</span> <span class="variable">job</span> <span class="operator">=</span> Job.getInstance(conf);</span><br><span class="line">		</span><br><span class="line">		<span class="comment">// 2 设置jar存储位置</span></span><br><span class="line">		<span class="comment">// setJar()表示设置固定的jar存储位置</span></span><br><span class="line">		<span class="comment">// setJarByClass()表示设置随主类变化的动态jar存储位置</span></span><br><span class="line">		job.setJarByClass(WordCountDriver.class);</span><br><span class="line">		</span><br><span class="line">		<span class="comment">// 3 关联Map和Reduce类</span></span><br><span class="line">		job.setMapperClass(WordCountMapper.class);</span><br><span class="line">		job.setReducerClass(WordCountReducer.class);</span><br><span class="line">		</span><br><span class="line">		<span class="comment">// 4  设置Mapper阶段输出数据的key和value类型</span></span><br><span class="line">		job.setMapOutputKeyClass(Text.class);</span><br><span class="line">		job.setMapOutputValueClass(IntWritable.class);</span><br><span class="line">		</span><br><span class="line">		<span class="comment">// 5 设置最终输出数据的key和value类型</span></span><br><span class="line">		job.setOutputKeyClass(Text.class);</span><br><span class="line">		job.setOutputValueClass(IntWritable.class);</span><br><span class="line">		</span><br><span class="line">		<span class="comment">// 6 设置输入路径和输出路径，路径设置为传参</span></span><br><span class="line">		FileInputFormat.setInputPaths(job, <span class="keyword">new</span> <span class="title class_">Path</span>(args[<span class="number">0</span>]));</span><br><span class="line">		</span><br><span class="line">		FileOutputFormat.setOutputPath(job, <span class="keyword">new</span> <span class="title class_">Path</span>(args[<span class="number">1</span>]));</span><br><span class="line">		</span><br><span class="line">		<span class="comment">// 7 提交job</span></span><br><span class="line">		<span class="comment">// job.submit();  过时方法</span></span><br><span class="line">		<span class="type">boolean</span> <span class="variable">result</span> <span class="operator">=</span> job.waitForCompletion(<span class="literal">true</span>); <span class="comment">// 如果传参为true，在成功提交后会打印相关信息</span></span><br><span class="line">		</span><br><span class="line">		System.exit(result? <span class="number">0</span> : <span class="number">1</span>);</span><br><span class="line">	&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<ol start="5">
<li><strong>本地测试</strong></li>
</ol>
<p>（1）如果电脑系统是win7的就将win7的hadoop jar包解压到非中文路径，并在Windows环境上配置HADOOP_HOME环境变量。如果是电脑win10操作系统，就解压win10的hadoop jar包，并配置HADOOP_HOME环境变量。</p>
<p><strong>Tip：win8电脑和win10家庭版操作系统可能有问题，需要重新编译源码或者更改操作系统。</strong></p>
<p>（2）在Eclipse&#x2F;Idea上运行程序，如图1.3：</p>
<p><img src="http://img.fdchen.host/RunConfiguration%E8%AE%BE%E7%BD%AE.jpg" alt="RunConfiguration设置"></p>
<center>图1.3 RunConfiguration设置</center>

<p><strong>Tip：输出路径目录必须未创建，不然会报错。</strong></p>
<ol start="6">
<li><strong>集群上测试</strong></li>
</ol>
<p>（0）用maven打jar包，需要添加的打包插件依赖</p>
<p><strong>Tip：</strong></p>
<ul>
<li><strong>标记红颜色的部分需要替换为自己工程主类。</strong></li>
<li><strong>如果工程上显示红叉。在项目上右键-&gt;maven-&gt;update project即可。</strong></li>
</ul>
<figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">build</span>&gt;</span></span><br><span class="line">		<span class="tag">&lt;<span class="name">plugins</span>&gt;</span></span><br><span class="line">			<span class="tag">&lt;<span class="name">plugin</span>&gt;</span></span><br><span class="line">				<span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>maven-compiler-plugin<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">				<span class="tag">&lt;<span class="name">version</span>&gt;</span>2.3.2<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line">				<span class="tag">&lt;<span class="name">configuration</span>&gt;</span></span><br><span class="line">					<span class="tag">&lt;<span class="name">source</span>&gt;</span>1.8<span class="tag">&lt;/<span class="name">source</span>&gt;</span></span><br><span class="line">					<span class="tag">&lt;<span class="name">target</span>&gt;</span>1.8<span class="tag">&lt;/<span class="name">target</span>&gt;</span></span><br><span class="line">				<span class="tag">&lt;/<span class="name">configuration</span>&gt;</span></span><br><span class="line">			<span class="tag">&lt;/<span class="name">plugin</span>&gt;</span></span><br><span class="line">			<span class="tag">&lt;<span class="name">plugin</span>&gt;</span></span><br><span class="line">				<span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>maven-assembly-plugin <span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">				<span class="tag">&lt;<span class="name">configuration</span>&gt;</span></span><br><span class="line">					<span class="tag">&lt;<span class="name">descriptorRefs</span>&gt;</span></span><br><span class="line">						<span class="tag">&lt;<span class="name">descriptorRef</span>&gt;</span>jar-with-dependencies<span class="tag">&lt;/<span class="name">descriptorRef</span>&gt;</span></span><br><span class="line">					<span class="tag">&lt;/<span class="name">descriptorRefs</span>&gt;</span></span><br><span class="line">					<span class="tag">&lt;<span class="name">archive</span>&gt;</span></span><br><span class="line">						<span class="tag">&lt;<span class="name">manifest</span>&gt;</span></span><br><span class="line">							<span class="tag">&lt;<span class="name">mainClass</span>&gt;</span>com.atguigu.mr.WordcountDriver<span class="tag">&lt;/<span class="name">mainClass</span>&gt;</span></span><br><span class="line">						<span class="tag">&lt;/<span class="name">manifest</span>&gt;</span></span><br><span class="line">					<span class="tag">&lt;/<span class="name">archive</span>&gt;</span></span><br><span class="line">				<span class="tag">&lt;/<span class="name">configuration</span>&gt;</span></span><br><span class="line">				<span class="tag">&lt;<span class="name">executions</span>&gt;</span></span><br><span class="line">					<span class="tag">&lt;<span class="name">execution</span>&gt;</span></span><br><span class="line">						<span class="tag">&lt;<span class="name">id</span>&gt;</span>make-assembly<span class="tag">&lt;/<span class="name">id</span>&gt;</span></span><br><span class="line">						<span class="tag">&lt;<span class="name">phase</span>&gt;</span>package<span class="tag">&lt;/<span class="name">phase</span>&gt;</span></span><br><span class="line">						<span class="tag">&lt;<span class="name">goals</span>&gt;</span></span><br><span class="line">							<span class="tag">&lt;<span class="name">goal</span>&gt;</span>single<span class="tag">&lt;/<span class="name">goal</span>&gt;</span></span><br><span class="line">						<span class="tag">&lt;/<span class="name">goals</span>&gt;</span></span><br><span class="line">					<span class="tag">&lt;/<span class="name">execution</span>&gt;</span></span><br><span class="line">				<span class="tag">&lt;/<span class="name">executions</span>&gt;</span></span><br><span class="line">			<span class="tag">&lt;/<span class="name">plugin</span>&gt;</span></span><br><span class="line">		<span class="tag">&lt;/<span class="name">plugins</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">build</span>&gt;</span></span><br></pre></td></tr></table></figure>

<p>（1）将程序打成jar包，然后拷贝到Hadoop集群中</p>
<p><strong>步骤详情：右键-&gt;Run as-&gt;maven install。</strong>等待编译完成就会在项目的target文件夹中生成jar包。如果看不到。在项目上右键–&gt;Refresh，即可看到。修改不带依赖的jar包名称为wc.jar，并拷贝该jar包到Hadoop集群。</p>
<p>（2）启动Hadoop集群，<strong>可以启动伪分布式模式，但是一定要先启动NameNode和DataNode进程，再启动yarn进程，否则DataNode进程会yarn进程被屏蔽。</strong></p>
<p>（3）执行WordCount程序</p>
<figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[<span class="type">atguigu</span>@<span class="type">hadoop102</span> <span class="type">hadoop</span>-<span class="number">2.7</span><span class="type">.2</span>]<span class="variable">$</span> hadoop jar wc.jar mr.WordCountDriver /user/atguigu/input /user/atguigu/output</span><br></pre></td></tr></table></figure>

<p><strong>Tip：</strong></p>
<ul>
<li><p><strong>com.atguigu.wordcount.WordcountDriver为驱动类的全类名，在Eclipse里面右键点击类名选择”Copy Qualified Name”即可。</strong></p>
</li>
<li><p><strong>输入输出路径是本地路径还是集群路径由集群的运行模式决定，如果是本地模式则输入本地路径，伪分布式和完全分布式输入集群路径。</strong></p>
</li>
<li><p><strong>如图1.4报错无法操作存储节点，原因是DataNode被yarn进程屏蔽</strong></p>
</li>
</ul>
<p><img src="/" alt="DataNode被yarn进程屏蔽报错无法操作存储节点"></p>
<center>图1.4 DataNode被yarn进程屏蔽报错无法操作存储节点</center>

<ul>
<li><strong>如图1.5报错无法连接，原因是未启动yarn</strong></li>
</ul>
<p><img src="http://img.fdchen.host/DataNode%E8%A2%AByarn%E8%BF%9B%E7%A8%8B%E5%B1%8F%E8%94%BD%E6%8A%A5%E9%94%99%E6%97%A0%E6%B3%95%E6%93%8D%E4%BD%9C%E9%9B%86%E7%BE%A4%E5%AD%98%E5%82%A8%E8%8A%82%E7%82%B9.jpg" alt="未启动yarn报错无法连接"></p>
<center>图1.5 未启动yarn报错无法连接</center>

<h1 id="2-Hadoop序列化"><a href="#2-Hadoop序列化" class="headerlink" title="2 Hadoop序列化"></a>2 Hadoop序列化</h1><h2 id="2-1-序列化概述"><a href="#2-1-序列化概述" class="headerlink" title="2.1 序列化概述"></a>2.1 序列化概述</h2><h3 id="2-1-1-什么是序列化"><a href="#2-1-1-什么是序列化" class="headerlink" title="2.1.1 什么是序列化"></a>2.1.1 什么是序列化</h3><ol>
<li><strong>序列化</strong>就是<strong>把内存中的对象，转换成字节序列（或其他数据传输协议）</strong>以便于存储到磁盘（持久化）和网络传输。</li>
<li><strong>反序列化</strong>就是将收到字节序列（或其他数据传输协议）或者是<strong>磁盘的持久化数据，转换成内存中的对象</strong>。</li>
</ol>
<h3 id="2-1-2-为什么要序列化"><a href="#2-1-2-为什么要序列化" class="headerlink" title="2.1.2 为什么要序列化"></a>2.1.2 为什么要序列化</h3><p>一般来说，“活的”对象只生存在内存里，关机断电就没有了。而且“活的”对象只能由本地的进程使用，不能被发送到网络上的另外一台计算机。然而<strong>序列化可以存储“活的”对象，可以将“活的”对象发送到远程计算机。</strong></p>
<h3 id="2-1-3-为什么不用Java的序列化"><a href="#2-1-3-为什么不用Java的序列化" class="headerlink" title="2.1.3 为什么不用Java的序列化"></a>2.1.3 为什么不用Java的序列化</h3><p>Java的序列化是一个重量级序列化框架(Serializable)，<strong>一个对象被序列化后，会附带很多额外的信息（各种校验信息，Header，继承体系等），不便于在网络中高效传输</strong>。所以，Hadoop自己开发了一套序列化机制(Writable) 。</p>
<h3 id="2-1-4-Hadoop排序列化特点"><a href="#2-1-4-Hadoop排序列化特点" class="headerlink" title="2.1.4 Hadoop排序列化特点"></a>2.1.4 Hadoop排序列化特点</h3><ul>
<li><strong>紧凑：</strong>高效使用存储空间。</li>
<li><strong>快速：</strong>读写数据的额外开销小。</li>
<li><strong>可扩展：</strong>可随着通信协议的升级而升级。</li>
<li><strong>互操作：</strong>支持多语言的交互。</li>
</ul>
<p><strong>Tip：读写数据的额外开销指的是由于提供检索而额外产生的存储开销等。</strong></p>
<h2 id="2-2-自定义bean对象实现序列化接口（Writable）"><a href="#2-2-自定义bean对象实现序列化接口（Writable）" class="headerlink" title="2.2 自定义bean对象实现序列化接口（Writable）"></a>2.2 自定义bean对象实现序列化接口（Writable）</h2><p>在企业开发中往往常用的基本序列化类型不能满足所有需求，比如在Hadoop框架内部传递一个bean对象，那么该对象就需要实现序列化接口。</p>
<p><strong>Tip：JavaBean简单的讲就是实体类，用来封装对象，这个类里面全部都是属性值和get，set方法。</strong></p>
<p>具体实现bean对象序列化步骤如下6步。</p>
<ol>
<li><p>必须实现Writable接口</p>
</li>
<li><p>反序列化时，需要反射调用空参构造函数，所以必须有空参构造</p>
</li>
</ol>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="title function_">FlowBean</span><span class="params">()</span> &#123;</span><br><span class="line">	<span class="built_in">super</span>();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<ol start="3">
<li>重写序列化方法</li>
</ol>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@Override</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">write</span><span class="params">(DataOutput out)</span> <span class="keyword">throws</span> IOException &#123;</span><br><span class="line">	out.writeLong(upFlow);</span><br><span class="line">	out.writeLong(downFlow);</span><br><span class="line">	out.writeLong(sumFlow);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<ol start="4">
<li>重写反序列化方法</li>
</ol>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@Override</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">readFields</span><span class="params">(DataInput in)</span> <span class="keyword">throws</span> IOException &#123;</span><br><span class="line">	upFlow = in.readLong();</span><br><span class="line">	downFlow = in.readLong();</span><br><span class="line">	sumFlow = in.readLong();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p><strong>Tip：注意反序列化的顺序和序列化的顺序要求完全一致，理由是序列化存储到磁盘采用的是队列式传输，先进先出，则先序列化的对象先存储，在磁盘读取时先反序列化最先序列化的对象。</strong></p>
<ol start="5">
<li><p>要想把结果显示在文件中，需要重写toString()，可用”\t”分开，方便后续用。</p>
</li>
<li><p>如果需要将自定义的bean放在key中传输，则还需要实现Comparable接口，因为<strong>MapReduce框中的Shuffle过程要求对key必须能排序</strong>。详见后面排序案例。</p>
</li>
</ol>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@Override</span></span><br><span class="line"><span class="keyword">public</span> <span class="type">int</span> <span class="title function_">compareTo</span><span class="params">(FlowBean o)</span> &#123;</span><br><span class="line">	<span class="comment">// 倒序排列，从大到小</span></span><br><span class="line">	<span class="keyword">return</span> <span class="built_in">this</span>.sumFlow &gt; o.getSumFlow() ? -<span class="number">1</span> : <span class="number">1</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h2 id="2-3-序列化案例实操"><a href="#2-3-序列化案例实操" class="headerlink" title="2.3 序列化案例实操"></a>2.3 序列化案例实操</h2><h3 id="2-3-1-需求"><a href="#2-3-1-需求" class="headerlink" title="2.3.1 需求"></a>2.3.1 需求</h3><ul>
<li>目标：统计每一个手机号耗费的总上行流量、下行流量、总流量。</li>
</ul>
<ol>
<li>输入数据：<a target="_blank" rel="noopener" href="http://img.fdchen.host/phone_data%20.txt">phone_data.txt</a></li>
<li>输入数据格式</li>
</ol>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">7 	13560436666	120.196.100.99		1116	 954		200</span><br><span class="line">id	手机号码		网络ip			上行流量  下行流量     网络状态码</span><br></pre></td></tr></table></figure>

<ol start="3">
<li>期望输出数据格式</li>
</ol>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">13560436666 	   1116		      954 			2070</span><br><span class="line">手机号码		    上行流量        下行流量		总流量</span><br></pre></td></tr></table></figure>

<h3 id="2-3-1-需求分析"><a href="#2-3-1-需求分析" class="headerlink" title="2.3.1 需求分析"></a>2.3.1 需求分析</h3><ol>
<li><strong>Map阶段</strong></li>
</ol>
<p>（1）读取一行数据，切分字段</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">7 	13560436666	120.196.100.99		1116	 954		200</span><br></pre></td></tr></table></figure>

<p>（2）抽取手机号、上行流量、下行流量</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">13560436666	   1116	    954</span><br><span class="line">手机号码		上行流量  下行流量</span><br></pre></td></tr></table></figure>

<p>（3）以手机号为key，bean对象为value输出，即context.write(手机号,bean);</p>
<p>（4）bean对象要想能够传输，必须实现序列化接口</p>
<ol start="2">
<li><strong>Reduce阶段</strong></li>
</ol>
<p>（1）累加上行流量和下行流量得到总流量。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">13560436666	   1116	 +  954   =  2070</span><br><span class="line">手机号码		上行流量  下行流量   总流量</span><br></pre></td></tr></table></figure>

<h3 id="2-3-3-编写MapReduce程序"><a href="#2-3-3-编写MapReduce程序" class="headerlink" title="2.3.3 编写MapReduce程序"></a>2.3.3 编写MapReduce程序</h3><ol>
<li><strong>编写流量统计的Bean对象</strong></li>
</ol>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> java.io.DataInput;</span><br><span class="line"><span class="keyword">import</span> java.io.DataOutput;</span><br><span class="line"><span class="keyword">import</span> java.io.IOException;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.io.Writable;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 1 实现writable接口</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">FlowBean</span> <span class="keyword">implements</span> <span class="title class_">Writable</span>&#123;</span><br><span class="line">	</span><br><span class="line">	<span class="keyword">private</span> <span class="type">long</span> upFlow;</span><br><span class="line">	<span class="keyword">private</span> <span class="type">long</span> downFlow;</span><br><span class="line">	<span class="keyword">private</span> <span class="type">long</span> sumFlow;</span><br><span class="line">	</span><br><span class="line">	<span class="comment">// 2 反序列化时，需要反射调用空参构造函数，所以必须定义空参构造函数</span></span><br><span class="line">	<span class="keyword">public</span> <span class="title function_">FlowBean</span><span class="params">()</span> &#123;</span><br><span class="line">		<span class="built_in">super</span>();</span><br><span class="line">	&#125;</span><br><span class="line">	</span><br><span class="line">    <span class="comment">// 注意补充this.sumFlow = upFlow + downFlow;</span></span><br><span class="line">	<span class="keyword">public</span> <span class="title function_">FlowBean</span><span class="params">(<span class="type">long</span> upFlow, <span class="type">long</span> downFlow)</span> &#123;</span><br><span class="line">		<span class="built_in">super</span>();</span><br><span class="line">		<span class="built_in">this</span>.upFlow = upFlow;</span><br><span class="line">		<span class="built_in">this</span>.downFlow = downFlow;</span><br><span class="line">		<span class="built_in">this</span>.sumFlow = upFlow + downFlow;</span><br><span class="line">	&#125;</span><br><span class="line">	</span><br><span class="line">	<span class="comment">// 3  序列化方法</span></span><br><span class="line">	<span class="meta">@Override</span></span><br><span class="line">	<span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">write</span><span class="params">(DataOutput out)</span> <span class="keyword">throws</span> IOException &#123;</span><br><span class="line">		out.writeLong(upFlow);</span><br><span class="line">		out.writeLong(downFlow);</span><br><span class="line">		out.writeLong(sumFlow);</span><br><span class="line">	&#125;</span><br><span class="line">	</span><br><span class="line">	<span class="comment">// 4 反序列化方法</span></span><br><span class="line">	<span class="comment">// 反序列化方法读顺序必须和写序列化方法的写顺序必须一致</span></span><br><span class="line">	<span class="meta">@Override</span></span><br><span class="line">	<span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">readFields</span><span class="params">(DataInput in)</span> <span class="keyword">throws</span> IOException &#123;</span><br><span class="line">		<span class="built_in">this</span>.upFlow=in.readLong();</span><br><span class="line">		<span class="built_in">this</span>.downFlow=in.readLong();</span><br><span class="line">		<span class="built_in">this</span>.sumFlow=in.readLong();</span><br><span class="line">	&#125;</span><br><span class="line"></span><br><span class="line">	<span class="comment">// 6 编写toString方法，方便后续打印到文本，注意使用&quot;\t&quot;隔开</span></span><br><span class="line">	<span class="meta">@Override</span></span><br><span class="line">	<span class="keyword">public</span> String <span class="title function_">toString</span><span class="params">()</span> &#123;</span><br><span class="line">		<span class="keyword">return</span> upFlow + <span class="string">&quot;\t&quot;</span> + downFlow + <span class="string">&quot;\t&quot;</span> + sumFlow;</span><br><span class="line">	&#125;</span><br><span class="line"></span><br><span class="line">	<span class="keyword">public</span> <span class="type">long</span> <span class="title function_">getUpFlow</span><span class="params">()</span> &#123;</span><br><span class="line">		<span class="keyword">return</span> upFlow;</span><br><span class="line">	&#125;</span><br><span class="line"></span><br><span class="line">	<span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">setUpFlow</span><span class="params">(<span class="type">long</span> upFlow)</span> &#123;</span><br><span class="line">		<span class="built_in">this</span>.upFlow = upFlow;</span><br><span class="line">	&#125;</span><br><span class="line"></span><br><span class="line">	<span class="keyword">public</span> <span class="type">long</span> <span class="title function_">getDownFlow</span><span class="params">()</span> &#123;</span><br><span class="line">		<span class="keyword">return</span> downFlow;</span><br><span class="line">	&#125;</span><br><span class="line"></span><br><span class="line">	<span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">setDownFlow</span><span class="params">(<span class="type">long</span> downFlow)</span> &#123;</span><br><span class="line">		<span class="built_in">this</span>.downFlow = downFlow;</span><br><span class="line">	&#125;</span><br><span class="line"></span><br><span class="line">	<span class="keyword">public</span> <span class="type">long</span> <span class="title function_">getSumFlow</span><span class="params">()</span> &#123;</span><br><span class="line">		<span class="keyword">return</span> sumFlow;</span><br><span class="line">	&#125;</span><br><span class="line"></span><br><span class="line">	<span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">setSumFlow</span><span class="params">(<span class="type">long</span> sumFlow)</span> &#123;</span><br><span class="line">		<span class="built_in">this</span>.sumFlow = sumFlow;</span><br><span class="line">	&#125;</span><br><span class="line">	</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p><strong>Tip：构造函数和get与set方法可以由Eclipse自动生成，点击右键–&gt;”source”–&gt;选择想要生成的方法，然后选择需要传入的参数即可。</strong></p>
<ol start="2">
<li><strong>编写Mapper类</strong></li>
</ol>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> java.io.IOException;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.io.LongWritable;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.io.Text;</span><br><span class="line"><span class="comment">// 注意导入正确jar包，Text类的包很容易导入错误</span></span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.mapreduce.Mapper;</span><br><span class="line"></span><br><span class="line"><span class="comment">// LongWritable代表行的偏移量，Text代表这一行的内容</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">FlowCountMapper</span> <span class="keyword">extends</span> <span class="title class_">Mapper</span>&lt;LongWritable, Text, Text, FlowBean&gt;&#123;</span><br><span class="line">	</span><br><span class="line">	<span class="comment">// map方法需要循环多次调用，所以两个输出变量定义在map方法外</span></span><br><span class="line">	<span class="type">FlowBean</span> <span class="variable">v</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">FlowBean</span>();</span><br><span class="line">	<span class="type">Text</span> <span class="variable">k</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">Text</span>();		<span class="comment">// 用Text类型变量代表手机号</span></span><br><span class="line">	</span><br><span class="line">	<span class="comment">// 1 获取1行</span></span><br><span class="line">	<span class="meta">@Override</span></span><br><span class="line">	<span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">map</span><span class="params">(LongWritable key,Text value,Context context)</span> <span class="keyword">throws</span> IOException, InterruptedException &#123;</span><br><span class="line">		<span class="comment">// 1 获取1行</span></span><br><span class="line">		<span class="type">String</span> <span class="variable">line</span> <span class="operator">=</span> value.toString();</span><br><span class="line">		</span><br><span class="line">		<span class="comment">// 2 切割字段</span></span><br><span class="line">		String[] fields = line.split(<span class="string">&quot;\t&quot;</span>);</span><br><span class="line">		</span><br><span class="line">		<span class="comment">// 3 封装对象</span></span><br><span class="line">		<span class="comment">// 取出手机号码</span></span><br><span class="line">		<span class="type">String</span> <span class="variable">phoneNum</span> <span class="operator">=</span> fields[<span class="number">1</span>];</span><br><span class="line">		</span><br><span class="line">		<span class="comment">// 取出上行流量和下行流量</span></span><br><span class="line">		<span class="type">long</span> <span class="variable">upFlow</span> <span class="operator">=</span> Long.parseLong(fields[fields.length-<span class="number">3</span>]);</span><br><span class="line">		<span class="type">long</span> <span class="variable">downFlow</span> <span class="operator">=</span> Long.parseLong(fields[fields.length-<span class="number">2</span>]);</span><br><span class="line">		</span><br><span class="line">		k.set(phoneNum);</span><br><span class="line">		<span class="comment">// v.setUpFlow(upFlow);</span></span><br><span class="line">		<span class="comment">// v.setDownFlow(downFlow);</span></span><br><span class="line">		<span class="comment">// 也可在FlowBean里面定义set(downFlow,upFlow);</span></span><br><span class="line">		v.set(upFlow,downFlow);</span><br><span class="line">		</span><br><span class="line">		<span class="comment">// 4 写出</span></span><br><span class="line">		context.write(k, v);</span><br><span class="line">	&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<ol start="3">
<li><strong>编写Reducer类</strong></li>
</ol>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> java.io.IOException;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.io.Text;</span><br><span class="line"><span class="comment">// 注意导入正确jar包，Text类的包很容易导入错误</span></span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.mapreduce.Reducer;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">FlowCountReducer</span> <span class="keyword">extends</span> <span class="title class_">Reducer</span>&lt;Text, FlowBean, Text, FlowBean&gt;&#123;</span><br><span class="line">	<span class="meta">@Override</span></span><br><span class="line">	<span class="keyword">protected</span> <span class="keyword">void</span> <span class="title function_">reduce</span><span class="params">(Text key, Iterable&lt;FlowBean&gt; values, Context context)</span> <span class="keyword">throws</span> IOException, InterruptedException &#123;</span><br><span class="line">		<span class="type">long</span> sum_upFlow=<span class="number">0</span>;</span><br><span class="line">		<span class="type">long</span> sum_downFlow=<span class="number">0</span>;</span><br><span class="line">		</span><br><span class="line">		<span class="comment">// 1 遍历所有bean，将其中的上行流量，下行流量分别累加</span></span><br><span class="line">		<span class="keyword">for</span>(FlowBean flowBean:values) &#123;</span><br><span class="line">			sum_upFlow+=flowBean.getUpFlow();</span><br><span class="line">			sum_downFlow+=flowBean.getDownFlow();</span><br><span class="line">		&#125;</span><br><span class="line">		</span><br><span class="line">		<span class="comment">// 2 封装对象</span></span><br><span class="line">		<span class="type">FlowBean</span> <span class="variable">resultBean</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">FlowBean</span>(sum_upFlow,sum_downFlow);</span><br><span class="line">		</span><br><span class="line">		<span class="comment">// 3 写出</span></span><br><span class="line">		context.write(key, resultBean);</span><br><span class="line">	&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<ol start="4">
<li><strong>编写Driver驱动类</strong></li>
</ol>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> java.io.IOException;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.conf.Configuration;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.fs.Path;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.io.Text;</span><br><span class="line"><span class="comment">// 注意导入正确jar包，Text类的包很容易导入错误</span></span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.mapreduce.Job;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.mapreduce.lib.input.FileInputFormat;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.mapreduce.lib.output.FileOutputFormat;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">FlowCountDriver</span> &#123;</span><br><span class="line">	<span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title function_">main</span><span class="params">(String args[])</span> <span class="keyword">throws</span> IllegalArgumentException, IOException, ClassNotFoundException, InterruptedException &#123;</span><br><span class="line">		<span class="comment">// 加入此行代码后在本地测试时不必再设置run configuration</span></span><br><span class="line">        <span class="comment">// 但在集群运行时需要把此行代码删去</span></span><br><span class="line">		args = <span class="keyword">new</span> <span class="title class_">String</span>[] &#123;<span class="string">&quot;d:/input/inputFlow&quot;</span>,<span class="string">&quot;d:/outputFlow&quot;</span>&#125;;</span><br><span class="line">		</span><br><span class="line">		<span class="type">Configuration</span> <span class="variable">conf</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">Configuration</span>();</span><br><span class="line">		<span class="comment">// 1 获取job对象</span></span><br><span class="line">		Job job=Job.getInstance(conf);</span><br><span class="line">		</span><br><span class="line">		<span class="comment">// 2 设置jar路径</span></span><br><span class="line">		job.setJarByClass(FlowCountDriver.class);</span><br><span class="line">		</span><br><span class="line">		<span class="comment">// 3 关联mapper和reducer</span></span><br><span class="line">		job.setMapperClass(FlowCountMapper.class);</span><br><span class="line">		job.setReducerClass(FlowCountReducer.class);</span><br><span class="line">		</span><br><span class="line">		<span class="comment">// 4 设置mapper输出的key和value类型</span></span><br><span class="line">		job.setMapOutputKeyClass(Text.class);</span><br><span class="line">		job.setMapOutputValueClass(FlowBean.class);</span><br><span class="line">		</span><br><span class="line">		<span class="comment">// 5 设置最终输出的key和value类型</span></span><br><span class="line">		job.setOutputKeyClass(Text.class);</span><br><span class="line">		job.setOutputValueClass(Text.class);</span><br><span class="line">		</span><br><span class="line">		<span class="comment">// 6 设置输入输出路径</span></span><br><span class="line">		FileInputFormat.setInputPaths(job, <span class="keyword">new</span> <span class="title class_">Path</span>(args[<span class="number">0</span>]));</span><br><span class="line">		FileOutputFormat.setOutputPath(job, <span class="keyword">new</span> <span class="title class_">Path</span>(args[<span class="number">1</span>]));</span><br><span class="line">		</span><br><span class="line">		<span class="comment">// 7 提交job</span></span><br><span class="line">		<span class="type">boolean</span> <span class="variable">result</span> <span class="operator">=</span> job.waitForCompletion(<span class="literal">true</span>);</span><br><span class="line">		</span><br><span class="line">		System.exit(result?<span class="number">0</span>:<span class="number">1</span>);</span><br><span class="line">	&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h1 id="3-MapReduce框架原理"><a href="#3-MapReduce框架原理" class="headerlink" title="3 MapReduce框架原理"></a>3 MapReduce框架原理</h1><h2 id="3-1-InputFormat数据输入"><a href="#3-1-InputFormat数据输入" class="headerlink" title="3.1 InputFormat数据输入"></a>3.1 InputFormat数据输入</h2><h3 id="3-1-1-切片与MapTask并行度决定机制"><a href="#3-1-1-切片与MapTask并行度决定机制" class="headerlink" title="3.1.1 切片与MapTask并行度决定机制"></a>3.1.1 切片与MapTask并行度决定机制</h3><ol>
<li>问题引出</li>
</ol>
<ul>
<li>MapTask的并行度决定Map阶段的任务处理并发度，进而影响到整个Job的处理速度。</li>
<li>1G的数据，启动8个MapTask，可以提高集群的并发处理能力。那么1K的数据，也启动8个MapTask，会提高集群性能吗？MapTask并行任务是否越多越好呢？哪些因素影响了MapTask并行度？</li>
</ul>
<ol start="2">
<li>MapTask并行度决定机制</li>
</ol>
<ul>
<li><strong>数据块：</strong>Block是HDFS物理上把数据分成一块一块。</li>
<li><strong>数据切片：</strong>数据切片只是在逻辑上对输入进行分片，并不会在磁盘上将其切分成片进行存储。</li>
<li>MapTask并行度决定机制如图3.1：</li>
</ul>
<p><img src="http://img.fdchen.host/MapTask%E5%B9%B6%E8%A1%8C%E5%BA%A6%E5%86%B3%E5%AE%9A%E6%9C%BA%E5%88%B6.png" alt="MapTask并行度决定机制"></p>
<center>图3.1 MapTask并行度决定机制</center>

<ul>
<li>当切片大小为BlockSize时效率最高，因为此时的I&#x2F;O开销很小。</li>
</ul>
<h3 id="3-1-2-Job提交流程源码和切片源码详解"><a href="#3-1-2-Job提交流程源码和切片源码详解" class="headerlink" title="3.1.2 Job提交流程源码和切片源码详解"></a>3.1.2 Job提交流程源码和切片源码详解</h3><ol>
<li><strong>Job提交流程源码详解</strong></li>
</ol>
<p>（1）源码结构如下：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><span class="line">waitForCompletion()</span><br><span class="line"></span><br><span class="line">submit();</span><br><span class="line"></span><br><span class="line"><span class="comment">// 1建立连接</span></span><br><span class="line">	connect();	</span><br><span class="line">		<span class="comment">// 1）创建提交Job的代理</span></span><br><span class="line">		<span class="keyword">new</span> <span class="title class_">Cluster</span>(getConfiguration());</span><br><span class="line">			<span class="comment">// （1）判断是本地yarn还是远程</span></span><br><span class="line">			initialize(jobTrackAddr, conf); </span><br><span class="line"></span><br><span class="line"><span class="comment">// 2 提交job</span></span><br><span class="line">submitter.submitJobInternal(Job.<span class="built_in">this</span>, cluster)</span><br><span class="line">	<span class="comment">// 1）创建给集群提交数据的Stag路径</span></span><br><span class="line">	<span class="type">Path</span> <span class="variable">jobStagingArea</span> <span class="operator">=</span> JobSubmissionFiles.getStagingDir(cluster, conf);</span><br><span class="line"></span><br><span class="line">	<span class="comment">// 2）获取jobid ，并创建Job路径</span></span><br><span class="line">	<span class="type">JobID</span> <span class="variable">jobId</span> <span class="operator">=</span> submitClient.getNewJobID();</span><br><span class="line"></span><br><span class="line">	<span class="comment">// 3）拷贝jar包到集群</span></span><br><span class="line">copyAndConfigureFiles(job, submitJobDir);	</span><br><span class="line">	rUploader.uploadFiles(job, jobSubmitDir);</span><br><span class="line"></span><br><span class="line"><span class="comment">// 4）计算切片，生成切片规划文件</span></span><br><span class="line">writeSplits(job, submitJobDir);</span><br><span class="line">		maps = writeNewSplits(job, jobSubmitDir);</span><br><span class="line">		input.getSplits(job);</span><br><span class="line"></span><br><span class="line"><span class="comment">// 5）向Stag路径写XML配置文件</span></span><br><span class="line">writeConf(conf, submitJobFile);</span><br><span class="line">	conf.writeXml(out);</span><br><span class="line"></span><br><span class="line"><span class="comment">// 6）提交Job,返回提交状态</span></span><br><span class="line">status = submitClient.submitJob(jobId, submitJobDir.toString(), job.getCredentials());</span><br></pre></td></tr></table></figure>

<p>（2）Job提交流程图解，如图3.2：</p>
<p><img src="http://img.fdchen.host/Job%E6%8F%90%E4%BA%A4%E6%B5%81%E7%A8%8B%E5%9B%BE%E8%A7%A3.png" alt="Job提交流程图解"></p>
<center>图3.2 Job提交流程图解</center>

<ol start="2">
<li><strong>FileInputFormat切片源码解析(input.getSplits(job))</strong></li>
</ol>
<p>（1）<strong>程序先找到数据存储的目录。</strong><br>（2）<strong>开始遍历处理（规划切片）目录下的每一个文件。</strong><br>（3）<strong>遍历第一个文件ss.txt</strong></p>
<ul>
<li>获取文件大小fs.sizeOf(ss.txt)；</li>
<li>计算切片大小；<br>computeSplitSize(Math.max(minSize, Math.min(maxSize, blocksze)))&#x3D;blocksize&#x3D;128M</li>
<li>默认情况下，切片大小&#x3D;blodksize；</li>
<li>开始切，形成第1个切片: ss.txt—0:128M第2个切片ss.txt—128:256M第3个切片ss.txt—256M:300M；<br>(每次切片时，都要判断切完剩下的部分是否大于块的1.1倍，不大于1.1倍就划分成一块切片</li>
<li>将切片信息写到一个切片规划文件中；</li>
<li>整个切片的核心过程在getSplit()方法中完成；</li>
<li>lnputSplit只记录了切片的元数据信息，比如起始位置、长度以及所在的节点列表等。</li>
</ul>
<p>（4）<strong>提交切片规划文件到YARN上，YARN上的MapReducer就可以很据切片规划文件计算开启MapTask个数。</strong></p>
<p><strong>Tip：本地模式的BlockSize为32M，Hadoop 1.x为64M，Hadoop 2.x为128M。</strong></p>
<h3 id="3-1-3-FileInputFormat切片机制"><a href="#3-1-3-FileInputFormat切片机制" class="headerlink" title="3.1.3 FileInputFormat切片机制"></a>3.1.3 FileInputFormat切片机制</h3><ol>
<li><strong>切片机制</strong></li>
</ol>
<p>（1）简单地按照文件的内容长度进行切片；</p>
<p>（2）切片大小，默认等于Block大小；</p>
<p>（3）切片时不考虑数据集整体，而是逐个针对每一个文件单独切片。</p>
<ol start="2">
<li><strong>FileInputFormat切片大小的参数配置</strong></li>
</ol>
<p>（1）<strong>源码中计算切片大小的公式</strong></p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">Math.max(minSize, Math.min(maxSize,blockSize));</span><br><span class="line"></span><br><span class="line"><span class="comment">// mapreduce.input.fileinputformat.split.minize=1，默认值为1</span></span><br><span class="line"><span class="comment">// mapreduce.input.fileinputformat.split.maxsize=Long.MAXValue，默认值是Long.MAXValue</span></span><br><span class="line"><span class="comment">// 默认情况下，切片大小=blockSize</span></span><br></pre></td></tr></table></figure>

<p>（2）<strong>切片大小设置</strong></p>
<p>maxsize（切片最大值）：参数如果调得比blockSize小，则会让切片变小，而且就等于配置的这个参数的值。</p>
<p>minsize（切片最小值）参数如果调得比blocksize大，则可以让切片变得比blockSize还大。</p>
<p>（3）<strong>获取切片信息API</strong></p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 获取切片的文件名称</span></span><br><span class="line"><span class="type">String</span> <span class="variable">name</span> <span class="operator">=</span> inputSplit.getPath().getName();</span><br><span class="line"><span class="comment">// 根据文件类型获取切片信息</span></span><br><span class="line"><span class="type">FileSplit</span> <span class="variable">inputSplit</span> <span class="operator">=</span> (FileSplit)context.getInputSplit();</span><br></pre></td></tr></table></figure>

<h3 id="3-1-4-CombineTextInputFormat切片机制"><a href="#3-1-4-CombineTextInputFormat切片机制" class="headerlink" title="3.1.4 CombineTextInputFormat切片机制"></a>3.1.4 CombineTextInputFormat切片机制</h3><p>框架默认的TextInputFormat切片机制是对任务按文件规划切片，<strong>不管文件多小，都会是一个单独的切片</strong>，都会交给一个MapTask，这样<strong>如果有大量小文件，就会产生大量的MapTask</strong>，处理效率极其低下。</p>
<ol>
<li><strong>应用场景</strong></li>
</ol>
<p>CombineTextInputFormat用于小文件过多的场景，它可以将多个小文件从逻辑上规划到一个切片中，这样，多个小文件就可以交给一个MapTask处理。</p>
<ol start="2">
<li><strong>虚拟存储切片最大值设置</strong></li>
</ol>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">CombineTextInputFormat.setMaxInputSplitSize(job, <span class="number">4194304</span>);   <span class="comment">// 4m</span></span><br></pre></td></tr></table></figure>

<p><strong>Tip：虚拟存储切片最大值设置最好根据实际的小文件大小分布情况来设置具体的值。</strong></p>
<ol start="3">
<li><strong>切片机制</strong></li>
</ol>
<ul>
<li>生成切片过程包括：<strong>虚拟存储过程和切片过程二部分</strong>。</li>
</ul>
<p><img src="http://img.fdchen.host/CombineTextInputFormat%E5%88%87%E7%89%87%E6%9C%BA%E5%88%B6.png" alt="CombineTextInputFormat切片机制"></p>
<center>图3.3 CombineTextInputFormat切片机制</center>

<p>（1）<strong>虚拟存储过程：</strong></p>
<p>将输入目录下所有文件大小，依次和设置的setMaxInputSplitSize值比较，如果不大于设置的最大值，逻辑上划分一个块。<strong>如果输入文件大于设置的最大值且大于两倍，那么以最大值切割一块；当剩余数据大小超过设置的最大值且不大于最大值2倍，此时将文件均分成2个虚拟存储块（防止出现太小切片）。</strong><br>例如setMaxInputSplitSize值为4M，输入文件大小为8.02M，则先逻辑上分成一个4M。剩余的大小为4.02M，如果按照4M逻辑划分，就会出现0.02M的小的虚拟存储文件，所以将剩余的4.02M文件切分成（2.01M和2.01M）两个文件。</p>
<p>（2）<strong>切片过程：</strong></p>
<p>（a）判断虚拟存储的文件大小是否大于setMaxInputSplitSize值，大于等于则单独形成一个切片。<br>（b）如果不大于则跟下一个虚拟存储文件进行合并，共同形成一个切片。<br>（c）测试举例：有4个小文件大小分别为1.7M、5.1M、3.4M以及6.8M这四个小文件，则虚拟存储之后形成6个文件块，大小分别为：<br>1.7M，（2.55M、2.55M），3.4M以及（3.4M、3.4M）<br>最终会形成3个切片，大小分别为：<br>（1.7+2.55）M，（2.55+3.4）M，（3.4+3.4）M</p>
<h3 id="3-1-5-CombineTextInputFormat案例实操"><a href="#3-1-5-CombineTextInputFormat案例实操" class="headerlink" title="3.1.5 CombineTextInputFormat案例实操"></a>3.1.5 CombineTextInputFormat案例实操</h3><ol>
<li><strong>需求：</strong>将输入的大量小文件合并成一个切片统一处理。</li>
</ol>
<p>（1）输入数据：准备4个小文件</p>
<p>（2）期望：期望1个切片处理4个文件</p>
<ol start="2">
<li><strong>实现过程</strong></li>
</ol>
<p>（1）<strong>不做任何处理，运行WordCount案例程序（自行准备4个小文件，大小对应3.1.4节中四个小文件大小），在控制台观察打印信息，显示切片个数为4。</strong></p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">number of splits:4</span><br></pre></td></tr></table></figure>

<p>（2）<strong>在WordcountDriver中增加如下代码，运行程序，并观察运行的切片个数为3。</strong></p>
<ul>
<li>在驱动类中添加代码如下：</li>
</ul>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 如果不设置InputFormat，它默认用的是TextInputFormat.class</span></span><br><span class="line">job.setInputFormatClass(CombineTextInputFormat.class);</span><br><span class="line"></span><br><span class="line"><span class="comment">//虚拟存储切片最大值设置4m</span></span><br><span class="line">CombineTextInputFormat.setMaxInputSplitSize(job, <span class="number">4194304</span>);</span><br></pre></td></tr></table></figure>

<ul>
<li>在控制台观察打印信息，运行结果为3个切片</li>
</ul>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">number of splits:3</span><br></pre></td></tr></table></figure>

<p>（3）<strong>在WordcountDriver中增加如下代码，运行程序，并观察运行的切片个数为1。</strong></p>
<ul>
<li>在驱动类中添加代码如下：</li>
</ul>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 如果不设置InputFormat，它默认用的是TextInputFormat.class</span></span><br><span class="line">job.setInputFormatClass(CombineTextInputFormat.class);</span><br><span class="line"></span><br><span class="line"><span class="comment">//虚拟存储切片最大值设置20m</span></span><br><span class="line">CombineTextInpu</span><br></pre></td></tr></table></figure>

<ul>
<li>在控制台观察打印信息，运行结果为3个切片</li>
</ul>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">number of splits:1</span><br></pre></td></tr></table></figure>

<h3 id="3-1-6-FileInputFormat实现类"><a href="#3-1-6-FileInputFormat实现类" class="headerlink" title="3.1.6 FileInputFormat实现类"></a>3.1.6 FileInputFormat实现类</h3><ul>
<li><strong>Q：</strong>在运行MapReduce程序时，输入的文件格式包括:基于行的日志文件、二进制格式文件、数据库表等。那么，针对不同的数据类型，MapReduce是如何读取这些数据的呢?</li>
<li><strong>A：</strong>FileInputFormat常见的接口实现类包括：<strong>TextInputFormat 、KeyValueTextInputFormat、NLineInputF ormat、CombineTextInputFormat和自定义InputFormat</strong>等。</li>
</ul>
<p><strong>Tip：在Eclipse中点击FileInputFormat类，然后按下“CTRL+T”可查看FileInputFormat类的层级结构，如图3.4：</strong></p>
<p><img src="http://img.fdchen.host/FileInputFormat%E7%B1%BB%E7%9A%84%E5%B1%82%E7%BA%A7%E7%BB%93%E6%9E%84.jpg" alt="FileInputFormat类的层级结构"></p>
<center>图3.4 FileInputFormat类的层级结构</center>

<ol>
<li><strong>TextInputFormat</strong></li>
</ol>
<ul>
<li><p>TextInputFormat是默认的FileIrputFormat实现类。<strong>按行读取每条记录。键是存储该行在整个文件中的起始字节偏移量（相对于文档开始位置的偏移量，包括换行符和回车符），LongWritable类型。值是这行的内容，不包括任何行终止符（换行符和回车符〉，Text类型。</strong></p>
</li>
<li><p>文本示例如下：</p>
</li>
</ul>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">Rich learning form</span><br><span class="line">Intelligent learning engine</span><br><span class="line">Learning more convenient</span><br><span class="line">From the real demand for more close to the enterprise</span><br></pre></td></tr></table></figure>

<ul>
<li>每条记录表示为以下键&#x2F;值对：</li>
</ul>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">(0,Rich learning form)</span><br><span class="line">(19,Intelligent learning engine)</span><br><span class="line">(47,Learning more convenient)</span><br><span class="line">(72,From the real demand for more close to the enterprise)</span><br></pre></td></tr></table></figure>

<ol start="2">
<li><strong>KeyValueFormat实现类</strong></li>
</ol>
<ul>
<li>每一行均为一条记录，被分隔符分割为key , value。可以通过在驱动类中设置conf.set(KeyValueLineRecordReaderKEY_VALUE_SEFERATOR,”\t”);来设定分隔符。默认分隔符是tab (\t)。</li>
<li>以下是一个示例，输入是一个包含4条记录的分片。其中——&gt;表标一个(水平方向的)制表符。</li>
</ul>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">linel——&gt;Rich learning form</span><br><span class="line">linez——&gt;Intelligent learning engine</span><br><span class="line">line3——&gt;Learning more convenient</span><br><span class="line">line4——&gt;From the real demand for more close to the enterprise</span><br></pre></td></tr></table></figure>

<ul>
<li>每条记录表示为以下键&#x2F;值对</li>
</ul>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">(linel,Rich learning form )</span><br><span class="line">(line2,Intelligent learning enginej)</span><br><span class="line">(line3,Learning more convenient)</span><br><span class="line">(line4,From the real demand for more close to the enterprise)</span><br></pre></td></tr></table></figure>

<p><strong>Tip：此时的键是每行排在分隔符（制表符）之前的Text序列。</strong></p>
<ol start="3">
<li><strong>NLineInputFormat</strong></li>
</ol>
<ul>
<li>如果使用NlineInputFormat，代表每个map进程处理的InputSplit不再按Block块去划分，而是按NineInptFormat指定的行数N味划分。即输入文件的总行数N&#x3D;切片数，如果不整除，切片数&#x3D;商+1。</li>
<li>以下是一个示例，仍然以上面的4行输入为例：</li>
</ul>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">Rich learning form</span><br><span class="line">Intelligent learning engine</span><br><span class="line">Learning more convenient</span><br><span class="line">From the real demand for more close to the enterprise</span><br></pre></td></tr></table></figure>

<ul>
<li>例如，如果N是2，则每个输入分片包含2行，开启两个MapTask。</li>
</ul>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">(0,Rich learning form)</span><br><span class="line">(19,Intelligent learning engine)</span><br></pre></td></tr></table></figure>

<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">(47,Learning more convenient)</span><br><span class="line">(72,From the real demand for more close to the enterprise)</span><br></pre></td></tr></table></figure>

<p><strong>Tip：这里的键和值与TextInputFormat生成的一样。</strong></p>
<h3 id="3-1-7-KeyValueTextInputFormat使用案例"><a href="#3-1-7-KeyValueTextInputFormat使用案例" class="headerlink" title="3.1.7 KeyValueTextInputFormat使用案例"></a>3.1.7 KeyValueTextInputFormat使用案例</h3><ol>
<li><strong>需求：</strong>统计输入文件每一行的第一个单词相同的行数。</li>
</ol>
<p>（1）输入数据</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">banzhang ni hao</span><br><span class="line">xihuan hadoop banzhang</span><br><span class="line">banzhang ni hao</span><br><span class="line">xihuan hadoop banzhang</span><br></pre></td></tr></table></figure>

<p>（2）期望结果数据</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">banzhang	2</span><br><span class="line">xihuan	2</span><br></pre></td></tr></table></figure>

<ol start="2">
<li><strong>案例分析</strong></li>
</ol>
<p><img src="http://img.fdchen.host/KeyValueTextInputFormat%E4%BD%BF%E7%94%A8%E6%A1%88%E4%BE%8B%E5%88%86%E6%9E%90.png" alt="KeyValueTextInputFormat使用案例分析"></p>
<center>图3.5 KeyValueTextInputFormat使用案例分析</center>

<ol start="3">
<li><strong>编写代码</strong></li>
</ol>
<p>（1）编写Mapper类</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> java.io.IOException;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.io.LongWritable;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.io.Text;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.mapreduce.Mapper;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">KVTextMapper</span> <span class="keyword">extends</span> <span class="title class_">Mapper</span>&lt;Text, Text, Text, LongWritable&gt;&#123;</span><br><span class="line">	</span><br><span class="line">	<span class="comment">// 1 封装对象</span></span><br><span class="line">	<span class="type">LongWritable</span> <span class="variable">v</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">LongWritable</span>(<span class="number">1</span>);</span><br><span class="line">	</span><br><span class="line">	<span class="meta">@Override</span></span><br><span class="line">	<span class="keyword">protected</span> <span class="keyword">void</span> <span class="title function_">map</span><span class="params">(Text key, Text value, Context context)</span> <span class="keyword">throws</span> IOException, InterruptedException &#123;</span><br><span class="line">		<span class="comment">// 输入数据格式：bangzhang ni hao</span></span><br><span class="line">		</span><br><span class="line">		<span class="comment">// 2 写出</span></span><br><span class="line">		context.write(key, v);</span><br><span class="line">		</span><br><span class="line">	&#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>（2）编写Reducer类</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> java.io.IOException;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.io.LongWritable;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.io.Text;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.mapreduce.Reducer;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">KVTextReducer</span> <span class="keyword">extends</span> <span class="title class_">Reducer</span>&lt;Text, LongWritable, Text, LongWritable&gt;&#123;</span><br><span class="line">	</span><br><span class="line">	<span class="type">LongWritable</span> <span class="variable">v</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">LongWritable</span>();</span><br><span class="line">	</span><br><span class="line">	<span class="meta">@Override</span></span><br><span class="line">	<span class="keyword">protected</span> <span class="keyword">void</span> <span class="title function_">reduce</span><span class="params">(Text key, Iterable&lt;LongWritable&gt; values, Context context)</span> <span class="keyword">throws</span> IOException, InterruptedException &#123;</span><br><span class="line">		<span class="comment">// 输入数据格式：&lt;bangzhang, 1&gt;</span></span><br><span class="line">		</span><br><span class="line">		<span class="comment">// 1 求和统计</span></span><br><span class="line">		<span class="type">long</span> <span class="variable">sum</span> <span class="operator">=</span> <span class="number">0L</span>;</span><br><span class="line">		<span class="keyword">for</span>(LongWritable value:values) &#123;</span><br><span class="line">			<span class="comment">// get()方法获取LongWritable类型的值</span></span><br><span class="line">			sum += value.get();</span><br><span class="line">		&#125;</span><br><span class="line">		</span><br><span class="line">		v.set(sum);</span><br><span class="line">		</span><br><span class="line">		<span class="comment">// 2 输出</span></span><br><span class="line">		context.write(key, v);</span><br><span class="line">	&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>（3）编写Driver类</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> java.io.IOException;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.conf.Configuration;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.fs.Path;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.io.LongWritable;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.io.Text;</span><br><span class="line"><span class="comment">// 以下jar包务必保证正确，采用mapreduce下的jar包，mapred下的jar包已经过时</span></span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.mapreduce.Job;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.mapreduce.lib.input.FileInputFormat;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.mapreduce.lib.input.KeyValueLineRecordReader;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.mapreduce.lib.input.KeyValueTextInputFormat;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.mapreduce.lib.output.FileOutputFormat;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">KVTextDriver</span> &#123;</span><br><span class="line">	<span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title function_">main</span><span class="params">(String args[])</span> <span class="keyword">throws</span> IOException, ClassNotFoundException, InterruptedException &#123;</span><br><span class="line">		</span><br><span class="line">		<span class="comment">// 本地模式下设置输入输出路径</span></span><br><span class="line">		args = <span class="keyword">new</span> <span class="title class_">String</span>[] &#123;<span class="string">&quot;d:/input/inputKVText&quot;</span>,<span class="string">&quot;d:/outputKVText&quot;</span>&#125;;</span><br><span class="line">		</span><br><span class="line">		<span class="type">Configuration</span> <span class="variable">conf</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">Configuration</span>();</span><br><span class="line">		</span><br><span class="line">		<span class="comment">// 设置切割符号为空格</span></span><br><span class="line">		conf.set(KeyValueLineRecordReader.KEY_VALUE_SEPERATOR, <span class="string">&quot; &quot;</span>);</span><br><span class="line">		</span><br><span class="line">		<span class="comment">// 1  获取job对象</span></span><br><span class="line">		<span class="type">Job</span> <span class="variable">job</span> <span class="operator">=</span> Job.getInstance(conf);</span><br><span class="line">		</span><br><span class="line">		<span class="comment">// 2 设置jar包位置</span></span><br><span class="line">		job.setJarByClass(KVTextDriver.class);</span><br><span class="line">		</span><br><span class="line">		<span class="comment">// 3 关联Mapper类和Reducer类</span></span><br><span class="line">		job.setMapperClass(KVTextMapper.class);</span><br><span class="line">		job.setReducerClass(KVTextReducer.class);</span><br><span class="line">		</span><br><span class="line">		<span class="comment">// 4 设置Map阶段输出数据的key-value类型</span></span><br><span class="line">		job.setMapOutputKeyClass(Text.class);</span><br><span class="line">		job.setMapOutputValueClass(LongWritable.class);</span><br><span class="line">		</span><br><span class="line">		<span class="comment">// 5 设置最终输出数据的key-value类型</span></span><br><span class="line">		job.setOutputKeyClass(Text.class);</span><br><span class="line">		job.setOutputValueClass(LongWritable.class);</span><br><span class="line">		</span><br><span class="line">		<span class="comment">// 6 设置输入输出数据路径</span></span><br><span class="line">		FileInputFormat.setInputPaths(job, <span class="keyword">new</span> <span class="title class_">Path</span>(args[<span class="number">0</span>]));</span><br><span class="line">		</span><br><span class="line">		<span class="comment">// 设置输入格式</span></span><br><span class="line">		job.setInputFormatClass(KeyValueTextInputFormat.class);</span><br><span class="line">		</span><br><span class="line">		FileOutputFormat.setOutputPath(job, <span class="keyword">new</span> <span class="title class_">Path</span>(args[<span class="number">1</span>]));</span><br><span class="line">		</span><br><span class="line">		<span class="comment">// 7 提交</span></span><br><span class="line">		<span class="type">boolean</span> <span class="variable">result</span> <span class="operator">=</span> job.waitForCompletion(<span class="literal">true</span>);</span><br><span class="line">		</span><br><span class="line">		System.exit(result?<span class="number">0</span>:<span class="number">1</span>);</span><br><span class="line">	&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h3 id="3-1-8-NLineInputFormat使用案例"><a href="#3-1-8-NLineInputFormat使用案例" class="headerlink" title="3.1.8 NLineInputFormat使用案例"></a>3.1.8 NLineInputFormat使用案例</h3><ol>
<li><strong>需求：</strong>对每个单词进行个数统计，要求根据每个输入文件的行数来规定输出多少个切片。此案例要求每三行放入一个切片中。</li>
</ol>
<p>（1）输入数据</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">banzhang ni hao</span><br><span class="line">xihuan hadoop banzhang</span><br><span class="line">banzhang ni hao</span><br><span class="line">xihuan hadoop banzhang</span><br><span class="line">banzhang ni hao</span><br><span class="line">xihuan hadoop banzhang</span><br><span class="line">banzhang ni hao</span><br><span class="line">xihuan hadoop banzhang</span><br><span class="line">banzhang ni hao</span><br><span class="line">xihuan hadoop banzhang banzhang ni hao</span><br><span class="line">xihuan hadoop banzhang</span><br></pre></td></tr></table></figure>

<p>（2）期望输出数据</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">控制台显示：Number of splits:4</span><br><span class="line">文件输出：</span><br><span class="line">banzhang	12</span><br><span class="line">hadoop	6</span><br><span class="line">hao	6</span><br><span class="line">ni	6</span><br><span class="line">xihuan	6</span><br></pre></td></tr></table></figure>

<ol start="2">
<li><strong>需求分析</strong></li>
</ol>
<p><img src="http://img.fdchen.host/NLineInputFormat%E6%A1%88%E4%BE%8B%E5%88%86%E6%9E%90.png" alt="NLineInputFormat案例分析"></p>
<center>图3.6 NLineInputFormat案例分析</center>

<p>3 <strong>代码实现</strong></p>
<p>（1）编写Mapper类</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> java.io.IOException;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.io.LongWritable;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.io.Text;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.mapreduce.Mapper;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">NLineTextMapper</span> <span class="keyword">extends</span> <span class="title class_">Mapper</span>&lt;LongWritable, Text, Text, LongWritable&gt;&#123;</span><br><span class="line">	</span><br><span class="line">	<span class="comment">// 定义输出键值对</span></span><br><span class="line">	<span class="type">Text</span> <span class="variable">k</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">Text</span>();</span><br><span class="line">	<span class="type">LongWritable</span> <span class="variable">v</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">LongWritable</span>(<span class="number">1</span>);</span><br><span class="line">	</span><br><span class="line">	<span class="meta">@Override</span></span><br><span class="line">	<span class="keyword">protected</span> <span class="keyword">void</span> <span class="title function_">map</span><span class="params">(LongWritable key, Text value, Context context)</span> <span class="keyword">throws</span> IOException, InterruptedException &#123;</span><br><span class="line">		</span><br><span class="line">		<span class="comment">// 输入数据格式 Rich learning form</span></span><br><span class="line">		</span><br><span class="line">		<span class="comment">// 1 获取一行</span></span><br><span class="line">		<span class="type">String</span> <span class="variable">line</span> <span class="operator">=</span> value.toString();</span><br><span class="line">		</span><br><span class="line">		<span class="comment">// 2 按照空格切分</span></span><br><span class="line">		String[] splits = line.split(<span class="string">&quot; &quot;</span>);</span><br><span class="line">		</span><br><span class="line">		<span class="comment">// 3 循环写出</span></span><br><span class="line">		<span class="keyword">for</span>(<span class="type">int</span> i=<span class="number">0</span>;i&lt;splits.length;i++) &#123;</span><br><span class="line">			k.set(splits[i]);</span><br><span class="line">			</span><br><span class="line">			context.write(k, v);</span><br><span class="line">		&#125;</span><br><span class="line">		</span><br><span class="line">	&#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>（2）编写Reducer类</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> java.io.IOException;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.io.LongWritable;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.io.Text;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.mapreduce.Reducer;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment">// Reduce</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">NLineTextReducer</span> <span class="keyword">extends</span> <span class="title class_">Reducer</span>&lt;Text, LongWritable, Text, LongWritable&gt;&#123;</span><br><span class="line">	</span><br><span class="line">	<span class="type">LongWritable</span> <span class="variable">v</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">LongWritable</span>();</span><br><span class="line">	</span><br><span class="line">	<span class="meta">@Override</span></span><br><span class="line">	<span class="keyword">protected</span> <span class="keyword">void</span> <span class="title function_">reduce</span><span class="params">(Text key,Iterable&lt;LongWritable&gt; values, Context context)</span> <span class="keyword">throws</span> IOException, InterruptedException &#123;</span><br><span class="line">		</span><br><span class="line">		<span class="comment">// 输入数据格式：&lt;Rich,1&gt; &lt;learning,1&gt;</span></span><br><span class="line">		</span><br><span class="line">		<span class="comment">// 1 汇总求和</span></span><br><span class="line">		<span class="type">long</span> <span class="variable">sum</span> <span class="operator">=</span> <span class="number">0L</span>;</span><br><span class="line">		<span class="keyword">for</span>(LongWritable value:values) &#123;</span><br><span class="line">			sum+=value.get();</span><br><span class="line">		&#125;</span><br><span class="line">		</span><br><span class="line">		v.set(sum);</span><br><span class="line">		</span><br><span class="line">		<span class="comment">// 2 输出</span></span><br><span class="line">		context.write(key, v);</span><br><span class="line">	&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>（3）编写Driver类</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> java.io.IOException;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.conf.Configuration;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.fs.Path;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.io.LongWritable;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.io.Text;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.mapreduce.Job;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.mapreduce.lib.input.FileInputFormat;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.mapreduce.lib.input.NLineInputFormat;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.mapreduce.lib.output.FileOutputFormat;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">NLineTextDriver</span> &#123;</span><br><span class="line">	<span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title function_">main</span><span class="params">(String args[])</span> <span class="keyword">throws</span> IOException, ClassNotFoundException, InterruptedException &#123;</span><br><span class="line">		</span><br><span class="line">		args=<span class="keyword">new</span> <span class="title class_">String</span>[] &#123;<span class="string">&quot;d:/input/inputNLineText&quot;</span>,<span class="string">&quot;d:/outputNLineText&quot;</span>&#125;;</span><br><span class="line">		</span><br><span class="line">		<span class="type">Configuration</span> <span class="variable">conf</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">Configuration</span>();</span><br><span class="line">		</span><br><span class="line">		<span class="comment">// 1 获取job对象</span></span><br><span class="line">		<span class="type">Job</span> <span class="variable">job</span> <span class="operator">=</span> Job.getInstance(conf);</span><br><span class="line">		</span><br><span class="line">		<span class="comment">// 2 设置jar包位置</span></span><br><span class="line">		job.setJarByClass(NLineTextDriver.class);</span><br><span class="line">		</span><br><span class="line">		<span class="comment">// 3 关联Mapper和Reducer类</span></span><br><span class="line">		job.setMapperClass(NLineTextMapper.class);</span><br><span class="line">		job.setReducerClass(NLineTextReducer.class);</span><br><span class="line">		</span><br><span class="line">		<span class="comment">// 4 设置Mpper阶段的输出key-value数据格式</span></span><br><span class="line">		job.setMapOutputKeyClass(Text.class);</span><br><span class="line">		job.setMapOutputValueClass(LongWritable.class);</span><br><span class="line">		</span><br><span class="line">		<span class="comment">// 5 设置最终输出key-value数据格式</span></span><br><span class="line">		job.setOutputKeyClass(Text.class);</span><br><span class="line">		job.setOutputValueClass(LongWritable.class);</span><br><span class="line">		</span><br><span class="line">		<span class="comment">// 6 设置输入输出路径，注意修改输入格式</span></span><br><span class="line">		FileInputFormat.setInputPaths(job, <span class="keyword">new</span> <span class="title class_">Path</span>(args[<span class="number">0</span>]));</span><br><span class="line">		</span><br><span class="line">		<span class="comment">// 设置输入格式</span></span><br><span class="line">		job.setInputFormatClass(NLineInputFormat.class);</span><br><span class="line">		</span><br><span class="line">		<span class="comment">// 设置每个切片划分三行记录</span></span><br><span class="line">		NLineInputFormat.setNumLinesPerSplit(job, <span class="number">3</span>);</span><br><span class="line">		</span><br><span class="line">		FileOutputFormat.setOutputPath(job, <span class="keyword">new</span> <span class="title class_">Path</span>(args[<span class="number">1</span>]));</span><br><span class="line">		</span><br><span class="line">		<span class="comment">// 7 提交</span></span><br><span class="line">		<span class="type">boolean</span> <span class="variable">result</span> <span class="operator">=</span> job.waitForCompletion(<span class="literal">true</span>);</span><br><span class="line">		</span><br><span class="line">		System.exit(result?<span class="number">0</span>:<span class="number">1</span>);</span><br><span class="line">	&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>（4）<strong>测试</strong></p>
<ul>
<li>输入数据如下</li>
</ul>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">banzhang ni hao</span><br><span class="line">xihuan hadoop banzhang</span><br><span class="line">banzhang ni hao</span><br><span class="line">xihuan hadoop banzhang</span><br><span class="line">banzhang ni hao</span><br><span class="line">xihuan hadoop banzhang</span><br><span class="line">banzhang ni hao</span><br><span class="line">xihuan hadoop banzhang</span><br><span class="line">banzhang ni hao</span><br><span class="line">xihuan hadoop banzhang banzhang ni hao</span><br><span class="line">xihuan hadoop banzhang</span><br></pre></td></tr></table></figure>

<ul>
<li>控制台运行结果如下</li>
</ul>
<p><img src="http://img.fdchen.host/NLineInputFormat%E4%BD%BF%E7%94%A8%E6%A1%88%E4%BE%8B%E8%BF%90%E8%A1%8C%E6%88%AA%E5%9B%BE.jpg" alt="NLineInputFormat使用案例运行截图"></p>
<center>图3.7 NLineInputFormat使用案例运行截图</center>

<ul>
<li>输出结果如下：</li>
</ul>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">banzhang	12</span><br><span class="line">hadoop	6</span><br><span class="line">hao	6</span><br><span class="line">ni	6</span><br><span class="line">xihuan	6</span><br></pre></td></tr></table></figure>

<h3 id="3-1-9-自定义InputFormat"><a href="#3-1-9-自定义InputFormat" class="headerlink" title="3.1.9 自定义InputFormat"></a>3.1.9 自定义InputFormat</h3><ul>
<li>在企业开发中，Hadoop框架自带的InputF ormmat类型不能满足所有应用场，需要自定义InputFormat来解决实际问题。</li>
<li>自定义InputFormat步骡如下:<br>（1）自定义一个类继承FileInputFormat。<br>（2）改写RecordReader，实现一次读取一个完整文件封装为KV。<br>（3）在输出时使用SequenceFileOutPutFormat输出合并文件。</li>
</ul>
<h3 id="3-1-10-自定义InputFormat案例实操"><a href="#3-1-10-自定义InputFormat案例实操" class="headerlink" title="3.1.10 自定义InputFormat案例实操"></a>3.1.10 自定义InputFormat案例实操</h3><ul>
<li>无论HDFS还是MapReduce，在处理小文件时效率都非常低，但又难免面临处理大量小文件的场景，此时，就需要有相应解决方案。可以自定义InputFormat实现小文件的合并。</li>
</ul>
<ol>
<li><strong>需求</strong></li>
</ol>
<p>将多个小文件合并成一个SequenceFile文件（<strong>SequenceFile文件是Hadoop用来存储二进制形式的key-value对的文件格式</strong>），SequenceFile里面存储着多个文件，<strong>存储的形式为文件路径+名称为key，文件内容为value</strong>。</p>
<p>（1）输入数据</p>
<ul>
<li>三个小文件：<a target="_blank" rel="noopener" href="http://img.fdchen.host/one.txt">one.txt</a>，<a target="_blank" rel="noopener" href="http://img.fdchen.host/two.txt">two.txt</a>，<a target="_blank" rel="noopener" href="http://img.fdchen.host/three.txt">three.txt</a></li>
</ul>
<p>（2）期望输出文件格式，SequenceFile文件</p>
<ul>
<li><a target="_blank" rel="noopener" href="http://img.fdchen.host/WholeFileInputFormat-part-r-00000">part-0000</a></li>
</ul>
<p>内容如下</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">SEQorg.apache.hadoop.io.Text&quot;org.apache.hadoop.io.BytesWritable      ?奀Wu授X@鼧?   W   &quot;!file:/e:/inputinputformat/one.txt   1yongpeng weidong weinan</span><br><span class="line">sanfeng luozong xiaoming   Y   $#file:/e:/inputinputformat/three.txt   1shuaige changmo zhenqiang </span><br><span class="line">dongli lingu xuanxuan   €   &quot;!file:/e:/inputinputformat/two.txt   Zlonglong fanfan</span><br><span class="line">mazong kailun yuhang yixin</span><br><span class="line">longlong fanfan</span><br><span class="line">mazong kailun yuhang yixin</span><br></pre></td></tr></table></figure>

<ol start="2">
<li><strong>需求分析</strong></li>
</ol>
<p><img src="http://img.fdchen.host/%E8%87%AA%E5%AE%9A%E4%B9%89InputFormat%E6%A1%88%E4%BE%8B%E5%88%86%E6%9E%90.png" alt="自定义InputFormat案例分析"></p>
<center>图3.8 自定义InputFormat案例分析</center>

<ol start="3">
<li><strong>程序实现</strong></li>
</ol>
<p>（1）自定义InputFormat</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> java.io.IOException;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.fs.Path;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.io.BytesWritable;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.io.Text;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.mapreduce.InputSplit;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.mapreduce.JobContext;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.mapreduce.RecordReader;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.mapreduce.TaskAttemptContext;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.mapreduce.lib.input.FileInputFormat;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">WholeFileInputFormat</span> <span class="keyword">extends</span> <span class="title class_">FileInputFormat</span>&lt;Text, BytesWritable&gt;&#123;</span><br><span class="line">	</span><br><span class="line">	<span class="comment">// 一定不能漏</span></span><br><span class="line">	<span class="meta">@Override</span></span><br><span class="line">	<span class="keyword">protected</span> <span class="type">boolean</span> <span class="title function_">isSplitable</span><span class="params">(JobContext context, Path filename)</span> &#123;</span><br><span class="line">		<span class="keyword">return</span> <span class="literal">false</span>;</span><br><span class="line">	&#125;</span><br><span class="line">	</span><br><span class="line">	<span class="meta">@Override</span></span><br><span class="line">	<span class="keyword">public</span> RecordReader&lt;Text, BytesWritable&gt; <span class="title function_">createRecordReader</span><span class="params">(InputSplit split, TaskAttemptContext context)</span></span><br><span class="line">			<span class="keyword">throws</span> IOException, InterruptedException &#123;</span><br><span class="line">		<span class="type">WholeRecordReader</span> <span class="variable">recordReader</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">WholeRecordReader</span>();</span><br><span class="line">		recordReader.initialize(split, context);</span><br><span class="line">		<span class="keyword">return</span> recordReader;</span><br><span class="line">	&#125;</span><br><span class="line">	</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>（2）自定义RecordReader类</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> java.io.IOException;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.conf.Configuration;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.fs.FSDataInputStream;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.fs.FileSystem;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.fs.Path;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.io.BytesWritable;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.io.IOUtils;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.io.Text;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.mapreduce.InputSplit;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.mapreduce.RecordReader;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.mapreduce.TaskAttemptContext;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.mapreduce.lib.input.FileSplit;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">WholeRecordReader</span> <span class="keyword">extends</span> <span class="title class_">RecordReader</span>&lt;Text, BytesWritable&gt;&#123;</span><br><span class="line"></span><br><span class="line">	FileSplit split;</span><br><span class="line">	Configuration configuration;</span><br><span class="line">	<span class="type">Text</span> <span class="variable">k</span> <span class="operator">=</span><span class="keyword">new</span> <span class="title class_">Text</span>();</span><br><span class="line">	<span class="type">BytesWritable</span> <span class="variable">v</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">BytesWritable</span>();</span><br><span class="line">	<span class="type">boolean</span> isProgress=<span class="literal">true</span>;  <span class="comment">// 依据map源码设置</span></span><br><span class="line">	</span><br><span class="line">	<span class="meta">@Override</span></span><br><span class="line">	<span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">initialize</span><span class="params">(InputSplit split, TaskAttemptContext context)</span> <span class="keyword">throws</span> IOException, InterruptedException &#123;</span><br><span class="line">		<span class="comment">// 初始化</span></span><br><span class="line">		<span class="built_in">this</span>.split=(FileSplit)split;</span><br><span class="line">		</span><br><span class="line">		<span class="comment">// 通过上下文获取配置信息</span></span><br><span class="line">		configuration = context.getConfiguration();</span><br><span class="line">	&#125;</span><br><span class="line"></span><br><span class="line">	<span class="meta">@Override</span></span><br><span class="line">	<span class="keyword">public</span> <span class="type">boolean</span> <span class="title function_">nextKeyValue</span><span class="params">()</span> <span class="keyword">throws</span> IOException, InterruptedException &#123;</span><br><span class="line">		<span class="comment">// 核心业务逻辑处理</span></span><br><span class="line">		</span><br><span class="line">		<span class="keyword">if</span>(isProgress) &#123;</span><br><span class="line">			<span class="type">byte</span>[] buf = <span class="keyword">new</span> <span class="title class_">byte</span>[(<span class="type">int</span>)split.getLength()];</span><br><span class="line">			</span><br><span class="line">			<span class="comment">// 1  获取fs对象</span></span><br><span class="line">			<span class="type">Path</span> <span class="variable">path</span> <span class="operator">=</span> split.getPath();</span><br><span class="line">			<span class="type">FileSystem</span> <span class="variable">fs</span> <span class="operator">=</span> path.getFileSystem(configuration);</span><br><span class="line">			</span><br><span class="line">			<span class="comment">// 2  获取输入流</span></span><br><span class="line">			<span class="type">FSDataInputStream</span> <span class="variable">fis</span> <span class="operator">=</span> fs.open(path);</span><br><span class="line">			</span><br><span class="line">			<span class="comment">// 3 拷贝</span></span><br><span class="line">			IOUtils.readFully(fis, buf , <span class="number">0</span>, buf.length);</span><br><span class="line">			</span><br><span class="line">			<span class="comment">// 4 封装v</span></span><br><span class="line">			v.set(buf, <span class="number">0</span>, buf.length);</span><br><span class="line">			</span><br><span class="line">			<span class="comment">// 5 封装k</span></span><br><span class="line">			k.set(path.toString());</span><br><span class="line">			</span><br><span class="line">			<span class="comment">// 6 关闭资源</span></span><br><span class="line">			IOUtils.closeStream(fis);</span><br><span class="line">			</span><br><span class="line">			isProgress=<span class="literal">false</span>;</span><br><span class="line">			</span><br><span class="line">			<span class="keyword">return</span> <span class="literal">true</span>;</span><br><span class="line">		&#125;</span><br><span class="line">		</span><br><span class="line">		<span class="keyword">return</span> <span class="literal">false</span>;</span><br><span class="line">	&#125;</span><br><span class="line"></span><br><span class="line">	<span class="meta">@Override</span></span><br><span class="line">	<span class="keyword">public</span> Text <span class="title function_">getCurrentKey</span><span class="params">()</span> <span class="keyword">throws</span> IOException, InterruptedException &#123;</span><br><span class="line">		</span><br><span class="line">		<span class="keyword">return</span> k;</span><br><span class="line">	&#125;</span><br><span class="line"></span><br><span class="line">	<span class="meta">@Override</span></span><br><span class="line">	<span class="keyword">public</span> BytesWritable <span class="title function_">getCurrentValue</span><span class="params">()</span> <span class="keyword">throws</span> IOException, InterruptedException &#123;</span><br><span class="line">		</span><br><span class="line">		<span class="keyword">return</span> v;</span><br><span class="line">	&#125;</span><br><span class="line"></span><br><span class="line">	<span class="meta">@Override</span></span><br><span class="line">	<span class="keyword">public</span> <span class="type">float</span> <span class="title function_">getProgress</span><span class="params">()</span> <span class="keyword">throws</span> IOException, InterruptedException &#123;</span><br><span class="line">		<span class="comment">// TODO Auto-generated method stub</span></span><br><span class="line">		<span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">	&#125;</span><br><span class="line"></span><br><span class="line">	<span class="meta">@Override</span></span><br><span class="line">	<span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">close</span><span class="params">()</span> <span class="keyword">throws</span> IOException &#123;</span><br><span class="line">		<span class="comment">// TODO Auto-generated method stub</span></span><br><span class="line">		</span><br><span class="line">	&#125;</span><br><span class="line">	</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p><strong>Tip：依据Mapper类的run函数源码，需要设置标志位来保证nextKeyValue只执行一次，即保证一个文件只读取一次。run函数源码如下：</strong></p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">run</span><span class="params">(Context context)</span> <span class="keyword">throws</span> IOException, InterruptedException &#123;</span><br><span class="line">  setup(context);</span><br><span class="line">  <span class="keyword">try</span> &#123;</span><br><span class="line">    <span class="keyword">while</span> (context.nextKeyValue()) &#123;</span><br><span class="line">      map(context.getCurrentKey(), context.getCurrentValue(), context);</span><br><span class="line">    &#125;</span><br><span class="line">  &#125; <span class="keyword">finally</span> &#123;</span><br><span class="line">    cleanup(context);</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>（3）编写Mapper类</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> java.io.IOException;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.io.BytesWritable;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.io.Text;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.mapreduce.Mapper;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">InputFormatMapper</span> <span class="keyword">extends</span> <span class="title class_">Mapper</span>&lt;Text, BytesWritable, Text, BytesWritable&gt;&#123;</span><br><span class="line">	<span class="meta">@Override</span></span><br><span class="line">	<span class="keyword">protected</span> <span class="keyword">void</span> <span class="title function_">map</span><span class="params">(Text key,BytesWritable value, Context context)</span> <span class="keyword">throws</span> IOException, InterruptedException &#123;</span><br><span class="line">		</span><br><span class="line">		<span class="comment">// 直接写出</span></span><br><span class="line">		context.write(key, value);</span><br><span class="line">	&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>（4）编写Reducer类</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> java.io.IOException;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.io.BytesWritable;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.io.Text;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.mapreduce.Reducer;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">InputFormatReducer</span> <span class="keyword">extends</span> <span class="title class_">Reducer</span>&lt;Text, BytesWritable, Text, BytesWritable&gt;&#123;</span><br><span class="line">	<span class="meta">@Override</span></span><br><span class="line">	<span class="keyword">protected</span> <span class="keyword">void</span> <span class="title function_">reduce</span><span class="params">(Text key,Iterable&lt;BytesWritable&gt; values, Context context)</span> <span class="keyword">throws</span> IOException, InterruptedException &#123;</span><br><span class="line">		</span><br><span class="line">		<span class="comment">// 循环写出</span></span><br><span class="line">        <span class="comment">// 因为Driver类中设置的输出类是SequenceFileOutputFormat类，所以Reducer输出只需要按文件名-文件内容的键值对形式输出即可</span></span><br><span class="line">		<span class="keyword">for</span>(BytesWritable value:values) &#123;</span><br><span class="line">			context.write(key, value);</span><br><span class="line">		&#125;</span><br><span class="line">	&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>（5）编写Driver类</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> java.io.IOException;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.conf.Configuration;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.fs.Path;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.io.BytesWritable;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.io.Text;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.mapreduce.Job;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.mapreduce.lib.input.FileInputFormat;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.mapreduce.lib.output.FileOutputFormat;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.mapreduce.lib.output.SequenceFileOutputFormat;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">InputFormatDriver</span> &#123;</span><br><span class="line">	<span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title function_">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> IOException, ClassNotFoundException, InterruptedException &#123;</span><br><span class="line">		</span><br><span class="line">	       <span class="comment">// 输入输出路径需要根据自己电脑上实际的输入输出路径设置</span></span><br><span class="line">			args = <span class="keyword">new</span> <span class="title class_">String</span>[] &#123; <span class="string">&quot;d:/input/inputInputFormat&quot;</span>, <span class="string">&quot;d:/outputInputFormat&quot;</span> &#125;;</span><br><span class="line"></span><br><span class="line">	       <span class="comment">// 1 获取job对象</span></span><br><span class="line">			<span class="type">Configuration</span> <span class="variable">conf</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">Configuration</span>();</span><br><span class="line">			<span class="type">Job</span> <span class="variable">job</span> <span class="operator">=</span> Job.getInstance(conf);</span><br><span class="line"></span><br><span class="line">	       <span class="comment">// 2 设置jar包存储位置、关联自定义的mapper和reducer</span></span><br><span class="line">			job.setJarByClass(InputFormatDriver.class);</span><br><span class="line">			job.setMapperClass(InputFormatMapper.class);</span><br><span class="line">			job.setReducerClass(InputFormatReducer.class);</span><br><span class="line"></span><br><span class="line">	       <span class="comment">// 7 设置输入的inputFormat，设置为自定义的InputFormat类</span></span><br><span class="line">			job.setInputFormatClass(WholeFileInputFormat.class);</span><br><span class="line"></span><br><span class="line">	       <span class="comment">// 8 设置输出的outputFormat，设置为SequenceFileOutputFormat类</span></span><br><span class="line">			job.setOutputFormatClass(SequenceFileOutputFormat.class);</span><br><span class="line">	       </span><br><span class="line">		   	<span class="comment">// 3 设置map输出端的kv类型</span></span><br><span class="line">			job.setMapOutputKeyClass(Text.class);</span><br><span class="line">			job.setMapOutputValueClass(BytesWritable.class);</span><br><span class="line">			</span><br><span class="line">	       <span class="comment">// 4 设置最终输出端的kv类型</span></span><br><span class="line">			job.setOutputKeyClass(Text.class);</span><br><span class="line">			job.setOutputValueClass(BytesWritable.class);</span><br><span class="line"></span><br><span class="line">	       <span class="comment">// 5 设置输入输出路径</span></span><br><span class="line">			FileInputFormat.setInputPaths(job, <span class="keyword">new</span> <span class="title class_">Path</span>(args[<span class="number">0</span>]));</span><br><span class="line">			FileOutputFormat.setOutputPath(job, <span class="keyword">new</span> <span class="title class_">Path</span>(args[<span class="number">1</span>]));</span><br><span class="line"></span><br><span class="line">	       <span class="comment">// 6 提交job</span></span><br><span class="line">			<span class="type">boolean</span> <span class="variable">result</span> <span class="operator">=</span> job.waitForCompletion(<span class="literal">true</span>);</span><br><span class="line">			System.exit(result ? <span class="number">0</span> : <span class="number">1</span>);</span><br><span class="line">		&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h2 id="3-2-MapReduce工作流程"><a href="#3-2-MapReduce工作流程" class="headerlink" title="3.2 MapReduce工作流程"></a>3.2 MapReduce工作流程</h2><h3 id="3-2-1-MapReduce工作流程示意图"><a href="#3-2-1-MapReduce工作流程示意图" class="headerlink" title="3.2.1 MapReduce工作流程示意图"></a>3.2.1 MapReduce工作流程示意图</h3><p><img src="http://img.fdchen.host/MapReduce%E5%B7%A5%E4%BD%9C%E6%B5%81%E7%A8%8B%EF%BC%88%E4%B8%80%EF%BC%89.png" alt="MapReduce工作流程（一）"></p>
<center>图3.9 MapReduce工作流程（一）</center>

<p><img src="http://img.fdchen.host/MapReduce%E5%B7%A5%E4%BD%9C%E6%B5%81%E7%A8%8B%EF%BC%88%E4%BA%8C%EF%BC%89.png" alt="MapReduce工作流程（二）"></p>
<center>图3.10 MapReduce工作流程（二）</center>

<h3 id="3-2-2-MapReduce工作流程详解"><a href="#3-2-2-MapReduce工作流程详解" class="headerlink" title="3.2.2 MapReduce工作流程详解"></a>3.2.2 MapReduce工作流程详解</h3><p>上面的流程是整个MapReduce最全工作流程，但是Shuffle过程只是从第7步开始到第16步结束，具体Shuffle过程详解，如下：</p>
<ol>
<li>MapTask收集我们的map()方法输出的kv对，放到内存缓冲区中；</li>
<li>从内存缓冲区不断溢出本地磁盘文件，可能会溢出多个文件；</li>
<li>多个溢出文件会被合并成大的溢出文件；</li>
<li>在溢出过程及合并的过程中，都要调用Partitioner进行分区和针对key进行排序；</li>
<li>ReduceTask根据自己的分区号，去各个MapTask机器上取相应的结果分区数据；</li>
<li>ReduceTask会取到同一个分区的来自不同MapTask的结果文件，ReduceTask会将这些文件再进行合并（归并排序）；</li>
<li>合并成大文件后，Shuffle的过程也就结束了，后面进入ReduceTask的逻辑运算过程（从文件中取出一个一个的键值对Group，调用用户自定义的reduce()方法）</li>
</ol>
<h3 id="3-2-3-注意点"><a href="#3-2-3-注意点" class="headerlink" title="3.2.3 注意点"></a>3.2.3 注意点</h3><ol>
<li><p>Shuffle中的缓冲区大小会影响到MapReduce程序的执行效率，原则上说，缓冲区越大，<strong>磁盘IO的次数越少，执行速度就越快</strong>。</p>
</li>
<li><p>缓冲区的大小可以通过参数调整，参数：io.sort.mb默认100M。</p>
</li>
</ol>
<h3 id="3-2-4-源码解析工作流程"><a href="#3-2-4-源码解析工作流程" class="headerlink" title="3.2.4 源码解析工作流程"></a>3.2.4 源码解析工作流程</h3><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 按照层级结构依次调用的主要函数如下</span></span><br><span class="line">context.write(k, NullWritable.get());</span><br><span class="line">	output.write(key, value);</span><br><span class="line">		collector.collect(key, value,partitioner.getPartition(key, value, partitions));</span><br><span class="line">			HashPartitioner();</span><br><span class="line">	collect()</span><br><span class="line">		close()</span><br><span class="line">			collect.flush()</span><br><span class="line">				sortAndSpill()</span><br><span class="line">					sort()   QuickSort</span><br><span class="line">				<span class="title function_">mergeParts</span><span class="params">()</span>;</span><br><span class="line">			collector.close();</span><br></pre></td></tr></table></figure>

<h2 id="3-3-Shuffle机制"><a href="#3-3-Shuffle机制" class="headerlink" title="3.3 Shuffle机制"></a>3.3 Shuffle机制</h2><h3 id="3-3-1-Shuffle机制"><a href="#3-3-1-Shuffle机制" class="headerlink" title="3.3.1 Shuffle机制"></a>3.3.1 Shuffle机制</h3><ul>
<li>Map方法之后，Reduce方法之前的数据处理过程称之为Shuffle。如图3.11所示：</li>
</ul>
<p><img src="http://img.fdchen.host/Shuffle%E6%9C%BA%E5%88%B6.png" alt="Shuffle机制"></p>
<center>图3.11 Shuffle机制</center>

<h3 id="3-3-2-Partition分区"><a href="#3-3-2-Partition分区" class="headerlink" title="3.3.2 Partition分区"></a>3.3.2 Partition分区</h3><ol>
<li><strong>分区概念：</strong>将统计结果输出到不同文件中（分区）。</li>
<li><strong>默认Partition分区</strong></li>
</ol>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">HashPartitioner</span>&lt;K,V&gt;<span class="keyword">extends</span> <span class="title class_">Partitioner</span>&lt;K,V&gt;&#123;</span><br><span class="line">    <span class="keyword">public</span> <span class="type">int</span> <span class="title function_">getPartition</span><span class="params">(R key, v value, <span class="type">int</span> numReduceTasks)</span> &#123;</span><br><span class="line">        <span class="keyword">return</span> (key.hashCode () &amp; Integer.MAX_VALUE) % numReduceTasks;</span><br><span class="line">        <span class="comment">// key.hashCode () &amp; Integer.MAX_VALUE是为了控制hashCode在int类型的取值范围内</span></span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<ul>
<li>默认分区是根据key日的hashCode对ReduceTasks个数取模得到的。用户没法控制哪个key存储到哪个分区。</li>
</ul>
<ol start="3">
<li><strong>自定义Partition步骤</strong></li>
</ol>
<p>（1）自定义类继承Partitioner，重写getPartition()方法</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// kv类型为map阶段输出数据的kv类型</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">CustonPartitioner</span> cxtends Partitioner&lt;Text,Flowbean&gt;&#123;</span><br><span class="line">	<span class="meta">@override</span></span><br><span class="line">	<span class="keyword">public</span> <span class="type">int</span> <span class="title function_">getPartition</span><span class="params">(Text key，FlowBean value, <span class="type">int</span> numPartitions)</span> &#123;</span><br><span class="line">        <span class="comment">// 控制分区代码逻辑</span></span><br><span class="line">        ······</span><br><span class="line">		<span class="keyword">return</span> partition; <span class="comment">// 分区索引从0开始计算</span></span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>（2）在Job驱动中，设置自定义Partitioner</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">job.setPartitionerClass(CustomPartitioner.class);</span><br></pre></td></tr></table></figure>

<p>（3）自定义Patition后，要根据自定义Partitiorer的逻辑设置相应数量的ReduceTask</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">job.setNumReduceTasks(<span class="number">5</span>);</span><br></pre></td></tr></table></figure>

<ol start="4">
<li><strong>分区总结</strong></li>
</ol>
<p>（1）如果<strong>ReduceTask的数量 &gt; getPatitian的结果数</strong>，则会多产生几个空的输出文件part-r-000xx；</p>
<p>（2）如果<strong>1&lt;ReduceTask的数量&lt;getPartition的结果数</strong>，则有一部分分区数据无处安放，会报错Exception；</p>
<p>（3）如果<strong>ReduceTask的数量&#x3D;1</strong>，则不管MapTask端输出多少个分区文件，最终结果都交给一个ReduceTask，最终也就具会产生一个结果文件part-r-00000；</p>
<p>（4）<strong>分区号必须从零开始，逐一累加。</strong></p>
<ol start="5">
<li><strong>案例分析</strong></li>
</ol>
<p>例如：假设自定义分区数为5，则<br>（1）job.setNumReduceTasks(1)，会正常运行，只不过会产生一个输出文件；</p>
<p>（2）job.setNumReduceTasks2)，会报错；</p>
<p>（3）job.setNumReduceTasks(6)；大于5，程序会正常运行，会产生空文件。</p>
<h3 id="3-3-3-Partition分区案例"><a href="#3-3-3-Partition分区案例" class="headerlink" title="3.3.3 Partition分区案例"></a>3.3.3 Partition分区案例</h3><ol>
<li><strong>需求：</strong>将统计结果按照手机归属地不同省份输出到不同文件中（分区）。</li>
</ol>
<p>（1）输入数据：<a target="_blank" rel="noopener" href="http://img.fdchen.host/phone_data.txt">phone_data.txt</a></p>
<p>（2）期望输出数据：手机号136、137、138、139开头都分别放到一个独立的4个文件中，其他开头的放到一个文件中。</p>
<ol start="2">
<li><strong>需求分析</strong></li>
</ol>
<p>（1）增加一个ProvicePartitioner进行自定义分区</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">136	分区0</span><br><span class="line">137	分区1</span><br><span class="line">138	分区2</span><br><span class="line">139	分区3</span><br><span class="line">其他	分区4</span><br></pre></td></tr></table></figure>

<p>（2）Driver驱动类修改</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 指定自定义数据分区</span></span><br><span class="line">job.setPartitionerClass(ProvincePartitioner.class);</span><br><span class="line">		</span><br><span class="line"><span class="comment">// 指定ReduceTask个数</span></span><br><span class="line">job.setNumReduceTasks(<span class="number">5</span>);</span><br></pre></td></tr></table></figure>

<ol start="3">
<li><strong>代码实现</strong></li>
</ol>
<p>（1）增加一个分区类ProvicePartitioner</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> org.apache.hadoop.io.Text;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.mapreduce.Partitioner;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">ProvincePartitioner</span> <span class="keyword">extends</span> <span class="title class_">Partitioner</span>&lt;Text, FlowBean&gt;&#123;</span><br><span class="line">	<span class="meta">@Override</span></span><br><span class="line">	<span class="keyword">public</span> <span class="type">int</span> <span class="title function_">getPartition</span><span class="params">(Text key,FlowBean value,<span class="type">int</span> numPartition)</span> &#123;</span><br><span class="line">		</span><br><span class="line">		<span class="comment">// 1 获取电话号码的前三位</span></span><br><span class="line">		String preNum=key.toString().substring(<span class="number">0</span>,<span class="number">3</span>);</span><br><span class="line">		</span><br><span class="line">		<span class="type">int</span> partition=<span class="number">4</span>;</span><br><span class="line">		</span><br><span class="line">		<span class="comment">// 2 判断是哪个省</span></span><br><span class="line">		<span class="keyword">if</span>(<span class="string">&quot;136&quot;</span>.equals(preNum)) &#123;</span><br><span class="line">			partition=<span class="number">0</span>;</span><br><span class="line">		&#125;<span class="keyword">else</span> <span class="keyword">if</span>(<span class="string">&quot;137&quot;</span>.equals(preNum)) &#123;</span><br><span class="line">			partition=<span class="number">1</span>;</span><br><span class="line">		&#125;<span class="keyword">else</span> <span class="keyword">if</span>(<span class="string">&quot;138&quot;</span>.equals(preNum)) &#123;</span><br><span class="line">			partition=<span class="number">2</span>;</span><br><span class="line">		&#125;<span class="keyword">else</span> <span class="keyword">if</span>(<span class="string">&quot;139&quot;</span>.equals(preNum))&#123;</span><br><span class="line">			partition=<span class="number">3</span>;</span><br><span class="line">		&#125;</span><br><span class="line">		</span><br><span class="line">		<span class="keyword">return</span> partition;</span><br><span class="line">	&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>（2）在驱动类中添加以下内容</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 设置partition类</span></span><br><span class="line">job.setPartitionerClass(ProvincePartitioner.class);</span><br><span class="line">		</span><br><span class="line"><span class="comment">// 设置ReduceTask个数</span></span><br><span class="line">job.setNumReduceTasks(<span class="number">5</span>);</span><br></pre></td></tr></table></figure>

<h3 id="3-3-4-WritableComparable排序"><a href="#3-3-4-WritableComparable排序" class="headerlink" title="3.3.4 WritableComparable排序"></a>3.3.4 WritableComparable排序</h3><ol start="0">
<li><strong>排序概述</strong></li>
</ol>
<p>（1）排序是MapReduce框架中最重要的操作之一。</p>
<p>（2）MapTask和ReduceTask均会对数据<strong>按照key进行排序</strong>。该操作属于Hadoop的默认行为。<strong>任何应用程序中的数据均会被排序，而不管逻辑上是否需要。</strong></p>
<p>（3）默认排序是<strong>按照字典顺序排序</strong>，且<strong>实现该排序的方法是快速排序</strong>。</p>
<p>（4）对于MapTask，它会将处理的结果暂时放到环形缓冲区中，<strong>当环形缓冲区使用率达到一定阈值后，再对缓冲区中的数据进行一次快速排序</strong>，并将这些有序数据溢写到磁盘上，而<strong>当数据处理完毕后，它会对磁盘上所有文件进行归并排序</strong>。<br>（5）对于ReduceTask，它从每个MapTask上远程拷贝相应的数据文件，如果文件大小超过一定阈值，则溢写磁盘上，否则存储在内存中。如果内存中文件大小或者数目超过一定阈值，则进行一次合并后将数据溢写到磁盘上；<strong>如果磁盘上文件数目达到一定阈值，则进行一次归并排序以生成一个更大文件（意味着如果文件不够多此部分可能没有）。当所有数据拷贝完毕后，ReduceTask统一对内存和磁盘上的所有数据进行一次归并排序。</strong></p>
<ol>
<li><strong>排序的分类</strong></li>
</ol>
<p>（1）<strong>部分排序</strong><br>MapReduce根据输入记录的键对数据集排序。保证输出的每个文件内部有序。<br>（2）<strong>全排序</strong><br>最终输出结果只有一个文件，且文件内部有序。实现方式是只设置一个ReduceTask。但该方法在处理大型文件时效率极低，因为一台机器处理所有文件，完全丧失了MapReduwe所提供的并行构。<br>（3）<strong>辅助排序（GroupingCormparator分组）</strong><br>在Reduce端对key进行分组。应用于：在接收的key为bean对象时，想让一个或几个字段相同（全部字段比较不相同）的key进入到同一个reduce方法时，可以采用分组非序。<br>（4）<strong>二次排序</strong><br>在自定义排序过程中，如果compareTo中的判断条件为两个即为二次排序。</p>
<ol start="2">
<li><strong>自定义排序WritableComparable</strong></li>
</ol>
<p>（1）bean对象做为key传输，需要实现WritableComparable接口重写compareTo方法，以实现排序。</p>
<p>（2）重写compareTo方法示例如下：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@Override</span></span><br><span class="line"><span class="keyword">public</span> <span class="type">int</span> <span class="title function_">compareTo</span><span class="params">(FlowBean o)</span> &#123;</span><br><span class="line"></span><br><span class="line">	<span class="type">int</span> result;</span><br><span class="line">		</span><br><span class="line">	<span class="comment">// 按照总流量大小，倒序排列</span></span><br><span class="line">	<span class="keyword">if</span> (sumFlow &gt; bean.getSumFlow()) &#123;</span><br><span class="line">		result = -<span class="number">1</span>;</span><br><span class="line">	&#125;<span class="keyword">else</span> <span class="keyword">if</span> (sumFlow &lt; bean.getSumFlow()) &#123;</span><br><span class="line">		result = <span class="number">1</span>;</span><br><span class="line">	&#125;<span class="keyword">else</span> &#123;</span><br><span class="line">		result = <span class="number">0</span>;</span><br><span class="line">	&#125;</span><br><span class="line"></span><br><span class="line">	<span class="keyword">return</span> result;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h3 id="3-3-5-WritableComparable排序案例实操（全排序）"><a href="#3-3-5-WritableComparable排序案例实操（全排序）" class="headerlink" title="3.3.5 WritableComparable排序案例实操（全排序）"></a>3.3.5 WritableComparable排序案例实操（全排序）</h3><ol>
<li><strong>需求：</strong>根据电话流量数据再次对总流量进行排序。</li>
</ol>
<p>（1）输入数据：<a target="_blank" rel="noopener" href="http://img.fdchen.host/phone_data.txt">phone_data</a></p>
<p>（2）期望输出数据</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">13509468723	7335	110349	117684</span><br><span class="line">13736230513	2481	24681	27162</span><br><span class="line">13956435636	132		1512	1644</span><br><span class="line">13846544121	264		0		264</span><br><span class="line">······</span><br></pre></td></tr></table></figure>

<ol start="2">
<li><strong>需求分析</strong></li>
</ol>
<p>（1）FlowBean实现WritableComparable接口重新compareTo方法</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@Override</span></span><br><span class="line"><span class="keyword">public</span> <span class="type">int</span> <span class="title function_">compareTo</span><span class="params">(FlowBean bean)</span> &#123;</span><br><span class="line">		</span><br><span class="line">	<span class="type">int</span> result;</span><br><span class="line">		</span><br><span class="line">	<span class="comment">// 核心比较条件判断</span></span><br><span class="line">	<span class="comment">// 按照总流量大小，倒序排列</span></span><br><span class="line">	<span class="keyword">if</span> (sumFlow &gt; bean.getSumFlow()) &#123;</span><br><span class="line">		result = -<span class="number">1</span>;</span><br><span class="line">	&#125;<span class="keyword">else</span> <span class="keyword">if</span> (sumFlow &lt; bean.getSumFlow()) &#123;</span><br><span class="line">		result = <span class="number">1</span>;</span><br><span class="line">	&#125;<span class="keyword">else</span> &#123;</span><br><span class="line">		result = <span class="number">0</span>;</span><br><span class="line">	&#125;</span><br><span class="line"></span><br><span class="line">	<span class="keyword">return</span> result;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>（2）Mapper类</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">context.write(bean,phoneNum)</span><br></pre></td></tr></table></figure>

<p>（3）Reudcer类</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 循环输出，避免总流量相同情况</span></span><br><span class="line"><span class="keyword">for</span>(Text text:values)&#123;</span><br><span class="line">    context.write(text,key)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<ol start="3">
<li><strong>代码实现</strong></li>
</ol>
<p>（1）FlowBean增加比较方法（重写之前的类，实现WritableComparable接口）</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> java.io.DataInput;</span><br><span class="line"><span class="keyword">import</span> java.io.DataOutput;</span><br><span class="line"><span class="keyword">import</span> java.io.IOException;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.io.WritableComparable;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">FlowBean</span> <span class="keyword">implements</span> <span class="title class_">WritableComparable</span>&lt;FlowBean&gt;&#123;</span><br><span class="line">	</span><br><span class="line">	<span class="keyword">private</span> <span class="type">long</span> upFlow;</span><br><span class="line">	<span class="keyword">private</span> <span class="type">long</span> downFlow;</span><br><span class="line">	<span class="keyword">private</span> <span class="type">long</span> sumFlow;</span><br><span class="line">	</span><br><span class="line">	<span class="comment">// 反序列化时，需要反射调用空参构造函数</span></span><br><span class="line">	<span class="keyword">public</span> <span class="title function_">FlowBean</span><span class="params">()</span> &#123;</span><br><span class="line">		<span class="built_in">super</span>();</span><br><span class="line">	&#125;</span><br><span class="line">	</span><br><span class="line">	</span><br><span class="line">	<span class="keyword">public</span> <span class="title function_">FlowBean</span><span class="params">(<span class="type">long</span> upFlow, <span class="type">long</span> downFlow)</span> &#123;</span><br><span class="line">		<span class="built_in">super</span>();</span><br><span class="line">		<span class="built_in">this</span>.upFlow = upFlow;</span><br><span class="line">		<span class="built_in">this</span>.downFlow = downFlow;</span><br><span class="line">		<span class="built_in">this</span>.sumFlow=upFlow+downFlow;</span><br><span class="line">	&#125;</span><br><span class="line">	</span><br><span class="line">	<span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">set</span><span class="params">(<span class="type">long</span> upFlow,<span class="type">long</span> downFlow)</span> &#123;</span><br><span class="line">		<span class="built_in">this</span>.upFlow=upFlow;</span><br><span class="line">		<span class="built_in">this</span>.downFlow=downFlow;</span><br><span class="line">		<span class="built_in">this</span>.sumFlow=upFlow+downFlow;</span><br><span class="line">	&#125;</span><br><span class="line"></span><br><span class="line">	<span class="keyword">public</span> <span class="type">long</span> <span class="title function_">getUpFlow</span><span class="params">()</span> &#123;</span><br><span class="line">		<span class="keyword">return</span> upFlow;</span><br><span class="line">	&#125;</span><br><span class="line"></span><br><span class="line">	<span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">setUpFlow</span><span class="params">(<span class="type">long</span> upFlow)</span> &#123;</span><br><span class="line">		<span class="built_in">this</span>.upFlow = upFlow;</span><br><span class="line">	&#125;</span><br><span class="line"></span><br><span class="line">	<span class="keyword">public</span> <span class="type">long</span> <span class="title function_">getDownFlow</span><span class="params">()</span> &#123;</span><br><span class="line">		<span class="keyword">return</span> downFlow;</span><br><span class="line">	&#125;</span><br><span class="line"></span><br><span class="line">	<span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">setDownFlow</span><span class="params">(<span class="type">long</span> downFlow)</span> &#123;</span><br><span class="line">		<span class="built_in">this</span>.downFlow = downFlow;</span><br><span class="line">	&#125;</span><br><span class="line"></span><br><span class="line">	<span class="keyword">public</span> <span class="type">long</span> <span class="title function_">getSumFlow</span><span class="params">()</span> &#123;</span><br><span class="line">		<span class="keyword">return</span> sumFlow;</span><br><span class="line">	&#125;</span><br><span class="line"></span><br><span class="line">	<span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">setSumFlow</span><span class="params">(<span class="type">long</span> sumFlow)</span> &#123;</span><br><span class="line">		<span class="built_in">this</span>.sumFlow = sumFlow;</span><br><span class="line">	&#125;</span><br><span class="line">	</span><br><span class="line">	<span class="comment">/**</span></span><br><span class="line"><span class="comment">	 * TASK 序列化方法</span></span><br><span class="line"><span class="comment">	 */</span></span><br><span class="line">	<span class="meta">@Override</span></span><br><span class="line">	<span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">write</span><span class="params">(DataOutput out)</span> <span class="keyword">throws</span> IOException &#123;</span><br><span class="line">		out.writeLong(upFlow);</span><br><span class="line">		out.writeLong(downFlow);</span><br><span class="line">		out.writeLong(sumFlow);</span><br><span class="line">	&#125;</span><br><span class="line"></span><br><span class="line">	<span class="comment">/**</span></span><br><span class="line"><span class="comment">	 * TASK 反序列化方法</span></span><br><span class="line"><span class="comment">	 */</span></span><br><span class="line">	<span class="meta">@Override</span></span><br><span class="line">	<span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">readFields</span><span class="params">(DataInput in)</span> <span class="keyword">throws</span> IOException &#123;</span><br><span class="line">		upFlow=in.readLong();</span><br><span class="line">		downFlow=in.readLong();</span><br><span class="line">		sumFlow=in.readLong();</span><br><span class="line">	&#125;</span><br><span class="line">	</span><br><span class="line">	<span class="meta">@Override</span></span><br><span class="line">	<span class="keyword">public</span> String <span class="title function_">toString</span><span class="params">()</span> &#123;</span><br><span class="line">		<span class="keyword">return</span> upFlow+<span class="string">&quot;\t&quot;</span>+downFlow+<span class="string">&quot;\t&quot;</span>+sumFlow;</span><br><span class="line">	&#125;</span><br><span class="line"></span><br><span class="line">	<span class="meta">@Override</span></span><br><span class="line">	<span class="keyword">public</span> <span class="type">int</span> <span class="title function_">compareTo</span><span class="params">(FlowBean bean)</span> &#123;</span><br><span class="line">		</span><br><span class="line">		<span class="type">int</span> result;</span><br><span class="line">		</span><br><span class="line">		<span class="comment">// 核心比较条件判断</span></span><br><span class="line">		<span class="comment">// 按照总流量大小，倒序排列</span></span><br><span class="line">		<span class="keyword">if</span> (sumFlow &gt; bean.getSumFlow()) &#123;</span><br><span class="line">			result = -<span class="number">1</span>;</span><br><span class="line">		&#125;<span class="keyword">else</span> <span class="keyword">if</span> (sumFlow &lt; bean.getSumFlow()) &#123;</span><br><span class="line">			result = <span class="number">1</span>;</span><br><span class="line">		&#125;<span class="keyword">else</span> &#123;</span><br><span class="line">			result = <span class="number">0</span>;</span><br><span class="line">		&#125;</span><br><span class="line"></span><br><span class="line">		<span class="keyword">return</span> result;</span><br><span class="line">	&#125;</span><br><span class="line">	</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>（2）编写Mapper类（重写之前的类，修改输出数据key和value的数据类型）</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> java.io.IOException;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.io.LongWritable;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.io.Text;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.mapreduce.Mapper;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">FlowCountSortMapper</span> <span class="keyword">extends</span> <span class="title class_">Mapper</span>&lt;LongWritable, Text, FlowBean, Text&gt;&#123;</span><br><span class="line">	<span class="type">FlowBean</span> <span class="variable">bean</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">FlowBean</span>();</span><br><span class="line">	<span class="type">Text</span> <span class="variable">v</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">Text</span>();</span><br><span class="line"></span><br><span class="line">	<span class="meta">@Override</span></span><br><span class="line">	<span class="keyword">protected</span> <span class="keyword">void</span> <span class="title function_">map</span><span class="params">(LongWritable key, Text value, Context context)</span>	<span class="keyword">throws</span> IOException, InterruptedException &#123;</span><br><span class="line"></span><br><span class="line">		<span class="comment">// 1 获取一行</span></span><br><span class="line">		<span class="type">String</span> <span class="variable">line</span> <span class="operator">=</span> value.toString();</span><br><span class="line">		</span><br><span class="line">		<span class="comment">// 2 截取</span></span><br><span class="line">		String[] fields = line.split(<span class="string">&quot;\t&quot;</span>);</span><br><span class="line">		</span><br><span class="line">		<span class="comment">// 3 封装对象</span></span><br><span class="line">		<span class="comment">// 取出手机号码</span></span><br><span class="line">		<span class="type">String</span> <span class="variable">phoneNum</span> <span class="operator">=</span> fields[<span class="number">1</span>];</span><br><span class="line">		</span><br><span class="line">		<span class="comment">// 取出上行流量和下行流量</span></span><br><span class="line">		<span class="type">long</span> <span class="variable">upFlow</span> <span class="operator">=</span> Long.parseLong(fields[fields.length-<span class="number">3</span>]);</span><br><span class="line">		<span class="type">long</span> <span class="variable">downFlow</span> <span class="operator">=</span> Long.parseLong(fields[fields.length-<span class="number">2</span>]);</span><br><span class="line">		</span><br><span class="line">		<span class="comment">// 不能仅仅设置sumFlow，因为bean对象在序列化时，变量必须有值</span></span><br><span class="line">		bean.set(upFlow, downFlow); </span><br><span class="line">		v.set(phoneNum);</span><br><span class="line">		</span><br><span class="line">		<span class="comment">// 4 输出，注意此时key-value的数据类型，总流量为key，电话号码为value</span></span><br><span class="line">		context.write(bean, v);</span><br><span class="line">	&#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>（3）编写Reducer类</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> java.io.IOException;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.io.Text;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.mapreduce.Reducer;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">FlowCountSortReducer</span> <span class="keyword">extends</span> <span class="title class_">Reducer</span>&lt;FlowBean, Text, Text, FlowBean&gt;&#123;</span><br><span class="line">	</span><br><span class="line">	<span class="meta">@Override</span></span><br><span class="line">	<span class="keyword">protected</span> <span class="keyword">void</span> <span class="title function_">reduce</span><span class="params">(FlowBean key, Iterable&lt;Text&gt; values, Context context)</span>	<span class="keyword">throws</span> IOException, InterruptedException &#123;</span><br><span class="line">		</span><br><span class="line">		<span class="comment">// 循环输出，避免总流量相同情况（总流量相同时，values的值有多个）</span></span><br><span class="line">		<span class="keyword">for</span> (Text text : values) &#123;</span><br><span class="line">			</span><br><span class="line">			<span class="comment">// 注意此时输出key-value的数据类型，与map阶段的数据类型相反</span></span><br><span class="line">			context.write(text, key);</span><br><span class="line">		&#125;</span><br><span class="line">	&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>（4）编写Driver类</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> java.io.IOException;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.conf.Configuration;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.fs.Path;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.io.Text;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.mapreduce.Job;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.mapreduce.lib.input.FileInputFormat;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.mapreduce.lib.output.FileOutputFormat;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">FlowCountSortDriver</span> &#123;</span><br><span class="line">	<span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title function_">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> ClassNotFoundException, IOException, InterruptedException &#123;</span><br><span class="line"></span><br><span class="line">		<span class="comment">// 输入输出路径需要根据自己电脑上实际的输入输出路径设置</span></span><br><span class="line">		args = <span class="keyword">new</span> <span class="title class_">String</span>[]&#123;<span class="string">&quot;d:/input/inputFlow&quot;</span>,<span class="string">&quot;d:/outputFlowCountSort&quot;</span>&#125;;</span><br><span class="line"></span><br><span class="line">		<span class="comment">// 1 获取配置信息，或者job对象实例</span></span><br><span class="line">		<span class="type">Configuration</span> <span class="variable">configuration</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">Configuration</span>();</span><br><span class="line">		<span class="type">Job</span> <span class="variable">job</span> <span class="operator">=</span> Job.getInstance(configuration);</span><br><span class="line"></span><br><span class="line">		<span class="comment">// 2 指定本程序的jar包所在的本地路径</span></span><br><span class="line">		job.setJarByClass(FlowCountSortDriver.class);</span><br><span class="line"></span><br><span class="line">		<span class="comment">// 3 指定本业务job要使用的mapper/Reducer业务类</span></span><br><span class="line">		job.setMapperClass(FlowCountSortMapper.class);</span><br><span class="line">		job.setReducerClass(FlowCountSortReducer.class);</span><br><span class="line"></span><br><span class="line">		<span class="comment">// 4 指定mapper输出数据的kv类型</span></span><br><span class="line">		job.setMapOutputKeyClass(FlowBean.class);</span><br><span class="line">		job.setMapOutputValueClass(Text.class);</span><br><span class="line"></span><br><span class="line">		<span class="comment">// 5 指定最终输出的数据的kv类型</span></span><br><span class="line">		job.setOutputKeyClass(Text.class);</span><br><span class="line">		job.setOutputValueClass(FlowBean.class);</span><br><span class="line"></span><br><span class="line">		<span class="comment">// 6 指定job的输入原始文件所在目录</span></span><br><span class="line">		FileInputFormat.setInputPaths(job, <span class="keyword">new</span> <span class="title class_">Path</span>(args[<span class="number">0</span>]));</span><br><span class="line">		FileOutputFormat.setOutputPath(job, <span class="keyword">new</span> <span class="title class_">Path</span>(args[<span class="number">1</span>]));</span><br><span class="line">		</span><br><span class="line">		<span class="comment">// 7 将job中配置的相关参数，以及job所用的java类所在的jar包， 提交给yarn去运行</span></span><br><span class="line">		<span class="type">boolean</span> <span class="variable">result</span> <span class="operator">=</span> job.waitForCompletion(<span class="literal">true</span>);</span><br><span class="line">		System.exit(result ? <span class="number">0</span> : <span class="number">1</span>);</span><br><span class="line">	&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<ol start="4">
<li><strong>总结</strong></li>
</ol>
<ul>
<li><strong>要实现依据总流量排序，在Map阶段的排序即可完成；</strong></li>
<li><strong>Reduce阶段的排序保证按规定顺序输出。</strong></li>
</ul>
<h3 id="3-3-6-WritableComparable排序案例实操（区内排序）"><a href="#3-3-6-WritableComparable排序案例实操（区内排序）" class="headerlink" title="3.3.6 WritableComparable排序案例实操（区内排序）"></a>3.3.6 WritableComparable排序案例实操（区内排序）</h3><ol>
<li><strong>需求：</strong>要求每个省份手机号输出的文件中按照总流量内部排序。。</li>
<li><strong>需求分析</strong></li>
</ol>
<ul>
<li><p>基于上一个需求（全排序），增加自定义分区类，分区按照省份手机号设置。</p>
</li>
<li><p>输入输出示例如图3.12：</p>
</li>
</ul>
<p><img src="http://img.fdchen.host/WritableComparable%E6%8E%92%E5%BA%8F%E6%A1%88%E4%BE%8B%EF%BC%88%E5%8C%BA%E5%86%85%E6%8E%92%E5%BA%8F%EF%BC%89%E8%BE%93%E5%85%A5%E8%BE%93%E5%87%BA%E7%A4%BA%E4%BE%8B.png" alt="WritableComparable排序案例（区内排序）输入输出示例"></p>
<center>图3.12 WritableComparable排序案例（区内排序）输入输出示例</center>

<ol start="3">
<li><strong>代码实现</strong></li>
</ol>
<p>（1）添加自定义分区类</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> org.apache.hadoop.io.Text;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.mapreduce.Partitioner;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 注意key-value类型</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">ProvincePartitioner</span> <span class="keyword">extends</span> <span class="title class_">Partitioner</span>&lt;FlowBean, Text&gt;&#123;</span><br><span class="line">	<span class="meta">@Override</span></span><br><span class="line">	<span class="keyword">public</span> <span class="type">int</span> <span class="title function_">getPartition</span><span class="params">(FlowBean key, Text value, <span class="type">int</span> numPartition)</span> &#123;</span><br><span class="line">		</span><br><span class="line">		<span class="comment">// 1 获取电话号码的前三位</span></span><br><span class="line">		String preNum=value.toString().substring(<span class="number">0</span>,<span class="number">3</span>);</span><br><span class="line">		</span><br><span class="line">		<span class="type">int</span> partition=<span class="number">4</span>;</span><br><span class="line">		</span><br><span class="line">		<span class="comment">// 2 判断是哪个省</span></span><br><span class="line">		<span class="keyword">if</span>(<span class="string">&quot;136&quot;</span>.equals(preNum)) &#123;</span><br><span class="line">			partition=<span class="number">0</span>;</span><br><span class="line">		&#125;<span class="keyword">else</span> <span class="keyword">if</span>(<span class="string">&quot;137&quot;</span>.equals(preNum)) &#123;</span><br><span class="line">			partition=<span class="number">1</span>;</span><br><span class="line">		&#125;<span class="keyword">else</span> <span class="keyword">if</span>(<span class="string">&quot;138&quot;</span>.equals(preNum)) &#123;</span><br><span class="line">			partition=<span class="number">2</span>;</span><br><span class="line">		&#125;<span class="keyword">else</span> <span class="keyword">if</span>(<span class="string">&quot;139&quot;</span>.equals(preNum))&#123;</span><br><span class="line">			partition=<span class="number">3</span>;</span><br><span class="line">		&#125;</span><br><span class="line">		</span><br><span class="line">		<span class="keyword">return</span> partition;</span><br><span class="line">	&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>（2）在Driver类中添加如下代码：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 设置自定义分区类</span></span><br><span class="line">job.setPartitionerClass(ProvincePartitioner.class);</span><br><span class="line">		</span><br><span class="line"><span class="comment">// 设置ReduceTask个数</span></span><br><span class="line">job.setNumReduceTasks(<span class="number">5</span>);</span><br></pre></td></tr></table></figure>

<h3 id="3-3-7-Combiner合并"><a href="#3-3-7-Combiner合并" class="headerlink" title="3.3.7 Combiner合并"></a>3.3.7 Combiner合并</h3><ol>
<li><p>Combiner是MR程序中Mapper和Reducer之外的一种组件。</p>
</li>
<li><p><strong>Combiner组件的父类就是Reducer。</strong></p>
</li>
<li><p>Combiner和Reducer的区别在于运行的位置：</p>
</li>
</ol>
<ul>
<li><strong>Combiner是在每一个MapTask所在的节点运行；</strong></li>
<li><strong>Reducer是接收全局所有Mapper的输出结果。</strong></li>
</ul>
<ol start="4">
<li>Combiner的意义就是<strong>对每一个MapTask的输出进行局部汇总</strong>，以减小网络传输量。</li>
<li>Combiner<strong>能够应用的前提是不能影响最终的业务逻辑</strong>，而且，Combiner的输出kv应该跟Reccer的输入kv类型要对应起来。</li>
</ol>
<ul>
<li>例如，Combiner适用于求和、汇总等场景，Combiner不适用求平均值场景，原因如图3.13：</li>
</ul>
<p><img src="http://img.fdchen.host/Combiner%E4%B8%8D%E9%80%82%E7%94%A8%E4%BA%8EMapReduce%E6%B1%82%E5%B9%B3%E5%9D%87%E5%80%BC%E5%9C%BA%E6%99%AF%E5%8E%9F%E5%9B%A0.jpg" alt="Combiner不适用于MapReduce求平均值场景原因"></p>
<center>图3.13 Combiner不适用于MapReduce求平均值场景原因</center>

<ol start="6">
<li>自定义Combiner实现步骤</li>
</ol>
<p>（1）自定义一个Combiner继承Reducer，重写Reduce方法</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> java.io.IOException;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.io.IntWritable;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.io.Text;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.mapreduce.Reducer;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">WordCountCombiner</span> <span class="keyword">extends</span> <span class="title class_">Reducer</span>&lt;Text, IntWritable, Text, IntWritable&gt;&#123;</span><br><span class="line">	</span><br><span class="line">	<span class="type">IntWritable</span>  <span class="variable">v</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">IntWritable</span>();</span><br><span class="line">	</span><br><span class="line">	<span class="meta">@Override</span></span><br><span class="line">	<span class="keyword">protected</span> <span class="keyword">void</span> <span class="title function_">reduce</span><span class="params">(Text key, Iterable&lt;IntWritable&gt; values, Context context)</span> <span class="keyword">throws</span> IOException, InterruptedException&#123;</span><br><span class="line">	</span><br><span class="line">		<span class="type">int</span> sum=<span class="number">0</span>;</span><br><span class="line">		</span><br><span class="line">		<span class="comment">// 1 累加求和</span></span><br><span class="line">		<span class="keyword">for</span>(IntWritable value:values) &#123;</span><br><span class="line">			sum += value.get();</span><br><span class="line">		&#125;</span><br><span class="line">		</span><br><span class="line">		v.set(sum);</span><br><span class="line">		</span><br><span class="line">		<span class="comment">// 2 写出atguigu 2</span></span><br><span class="line">		context.write(key, v);</span><br><span class="line">	&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>（2）在Driver类中设置：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 设置Combiner类</span></span><br><span class="line">job.setCombinerClass(WordCountCombiner.class);</span><br></pre></td></tr></table></figure>

<h3 id="3-3-8-Combiner合并案例实操"><a href="#3-3-8-Combiner合并案例实操" class="headerlink" title="3.3.8 Combiner合并案例实操"></a>3.3.8 Combiner合并案例实操</h3><ol>
<li><strong>需求：</strong>统计过程中对每一个MapTask的输出进行局部汇总，以减小网络传输量，即采用Combiner功能。</li>
</ol>
<p>（1）输入数据：<a href="">hello.txt</a></p>
<p>（2）期望输出：</p>
<p>Map阶段输出到Reduce阶段时经过合并，输出数据降低。</p>
<p>期望控制台显示如图3.13所示：</p>
<p><img src="http://img.fdchen.host/Combiner%E6%88%90%E5%8A%9F%E7%A4%BA%E4%BE%8B.jpg" alt="Combiner成功示例"></p>
<center>图3.13 Combiner成功示例</center>

<ol start="2">
<li><strong>需求分析</strong></li>
</ol>
<p>（1）方案一</p>
<ul>
<li>增加一个WordCombiner类继承Reducer类；</li>
<li>在WordCountCombiner中实现：统计单词汇总和统计结果输出。</li>
</ul>
<p>（2）方案二</p>
<ul>
<li>将WordCountReducer作为Combiner在WordCountDriver驱动类中指定</li>
</ul>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">job.setCombinerClass(WordCountReducer.class);</span><br></pre></td></tr></table></figure>

<ol start="3">
<li><strong>代码实现（方案一）</strong></li>
</ol>
<p>（1）增加一个WordcountCombiner类继承Reducer</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> java.io.IOException;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.io.IntWritable;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.io.Text;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.mapreduce.Reducer;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">WordCountCombiner</span> <span class="keyword">extends</span> <span class="title class_">Reducer</span>&lt;Text, IntWritable, Text, IntWritable&gt;&#123;</span><br><span class="line">	</span><br><span class="line">	<span class="type">IntWritable</span>  <span class="variable">v</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">IntWritable</span>();</span><br><span class="line">	</span><br><span class="line">	<span class="meta">@Override</span></span><br><span class="line">	<span class="keyword">protected</span> <span class="keyword">void</span> <span class="title function_">reduce</span><span class="params">(Text key, Iterable&lt;IntWritable&gt; values, Context context)</span> <span class="keyword">throws</span> IOException, InterruptedException&#123;</span><br><span class="line">	</span><br><span class="line">		<span class="type">int</span> sum=<span class="number">0</span>;</span><br><span class="line">		</span><br><span class="line">		<span class="comment">// 1 累加求和</span></span><br><span class="line">		<span class="keyword">for</span>(IntWritable value:values) &#123;</span><br><span class="line">			sum += value.get();</span><br><span class="line">		&#125;</span><br><span class="line">		</span><br><span class="line">		v.set(sum);</span><br><span class="line">	</span><br><span class="line">		context.write(key, v);</span><br><span class="line">	&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>（2）在WordcountDriver驱动类中指定Combiner</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 指定需要使用combiner，以及用哪个类作为combiner的逻辑</span></span><br><span class="line">job.setCombinerClass(WordcountCombiner.class);</span><br></pre></td></tr></table></figure>

<h3 id="3-3-9-GroupingComparator分组（辅助排序）"><a href="#3-3-9-GroupingComparator分组（辅助排序）" class="headerlink" title="3.3.9 GroupingComparator分组（辅助排序）"></a>3.3.9 GroupingComparator分组（辅助排序）</h3><ul>
<li>在Reduce阶段前，根据某一个或几个字段对Map阶段输出的有序键值对进行分组。</li>
<li>自定义分组排序步骤</li>
</ul>
<ol>
<li><p>自定义类继承WritableComparator</p>
</li>
<li><p>重写compare()方法</p>
</li>
</ol>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@Override</span> </span><br><span class="line"><span class="keyword">public</span> <span class="type">int</span> <span class="title function_">compare</span><span class="params">(WritableComparable a, WritableComparable b)</span> &#123;</span><br><span class="line"> </span><br><span class="line">		<span class="comment">// 比较的业务逻辑</span></span><br><span class="line">		<span class="keyword">return</span> result;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<ol start="3">
<li>创建一个构造方法，将比较对象的类传给父类</li>
</ol>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">protected</span> <span class="title function_">OrderGroupingComparator</span><span class="params">()</span> &#123;</span><br><span class="line">    </span><br><span class="line">   		<span class="built_in">super</span>(OrderBean.class, <span class="literal">true</span>);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h3 id="3-3-10-GroupingComparator分组案例实操"><a href="#3-3-10-GroupingComparator分组案例实操" class="headerlink" title="3.3.10 GroupingComparator分组案例实操"></a>3.3.10 GroupingComparator分组案例实操</h3><ol>
<li><strong>需求</strong></li>
</ol>
<p>（1）输入数据如下，要求输出每个订单中最贵的商品。</p>
<ul>
<li><a target="_blank" rel="noopener" href="http://img.fdchen.host/GroupingComparator.txt">GroupingComparator</a></li>
</ul>
<p>（2）期望输出数据</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">1	222.8</span><br><span class="line">2	722.4</span><br><span class="line">3	232.8</span><br></pre></td></tr></table></figure>

<ol start="2">
<li><strong>需求分析</strong></li>
</ol>
<p>（1）利用“订单id和成交金额”作为key，可以将Map阶段读取到的所有订单数据按照id升序排序，如果id相同再按照金额降序排序，发送到Reduce。</p>
<p>（2）在Reduce端利用groupingComparator将订单id相同的kv聚合成组，然后取第一个即是该订单中最贵商品，如图3.14所示。</p>
<p><img src="http://img.fdchen.host/GroupingComparator%E5%88%86%E7%BB%84%E6%A1%88%E4%BE%8B%E9%9C%80%E6%B1%82%E5%88%86%E6%9E%90.png" alt="GroupingComparator分组案例需求分析"></p>
<center>图3.14 GroupingComparator分组案例需求分析</center>

<ol start="3">
<li><strong>代码实现</strong></li>
</ol>
<p>（1）定义订单信息OrderBean类</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> java.io.DataInput;</span><br><span class="line"><span class="keyword">import</span> java.io.DataOutput;</span><br><span class="line"><span class="keyword">import</span> java.io.IOException;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.io.WritableComparable;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">OrderBean</span> <span class="keyword">implements</span> <span class="title class_">WritableComparable</span>&lt;OrderBean&gt;&#123;</span><br><span class="line"></span><br><span class="line">	<span class="keyword">private</span> <span class="type">int</span> order_id;</span><br><span class="line">	<span class="keyword">private</span> <span class="type">double</span> price;</span><br><span class="line">	</span><br><span class="line">	</span><br><span class="line">	<span class="comment">// 空参构造</span></span><br><span class="line">	<span class="keyword">public</span> <span class="title function_">OrderBean</span><span class="params">()</span> &#123;</span><br><span class="line">		<span class="built_in">super</span>();</span><br><span class="line">	&#125;</span><br><span class="line">	</span><br><span class="line">	<span class="comment">// 有参构造</span></span><br><span class="line">	<span class="keyword">public</span> <span class="title function_">OrderBean</span><span class="params">(<span class="type">int</span> order_id, <span class="type">double</span> price)</span> &#123;</span><br><span class="line">		<span class="built_in">super</span>();</span><br><span class="line">		<span class="built_in">this</span>.order_id = order_id;</span><br><span class="line">		<span class="built_in">this</span>.price = price;</span><br><span class="line">	&#125;</span><br><span class="line"></span><br><span class="line">	<span class="keyword">public</span> <span class="type">int</span> <span class="title function_">getOrder_id</span><span class="params">()</span> &#123;</span><br><span class="line">		<span class="keyword">return</span> order_id;</span><br><span class="line">	&#125;</span><br><span class="line"></span><br><span class="line">	<span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">setOrder_id</span><span class="params">(<span class="type">int</span> order_id)</span> &#123;</span><br><span class="line">		<span class="built_in">this</span>.order_id = order_id;</span><br><span class="line">	&#125;</span><br><span class="line"></span><br><span class="line">	<span class="keyword">public</span> <span class="type">double</span> <span class="title function_">getPrice</span><span class="params">()</span> &#123;</span><br><span class="line">		<span class="keyword">return</span> price;</span><br><span class="line">	&#125;</span><br><span class="line"></span><br><span class="line">	<span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">setPrice</span><span class="params">(<span class="type">double</span> price)</span> &#123;</span><br><span class="line">		<span class="built_in">this</span>.price = price;</span><br><span class="line">	&#125;</span><br><span class="line"></span><br><span class="line">	<span class="meta">@Override</span></span><br><span class="line">	<span class="keyword">public</span> String <span class="title function_">toString</span><span class="params">()</span> &#123;</span><br><span class="line">		<span class="keyword">return</span> order_id + <span class="string">&quot;\t&quot;</span> + price;</span><br><span class="line">	&#125;</span><br><span class="line"></span><br><span class="line">	<span class="meta">@Override</span></span><br><span class="line">	<span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">write</span><span class="params">(DataOutput out)</span> <span class="keyword">throws</span> IOException &#123;</span><br><span class="line">		out.writeInt(order_id);</span><br><span class="line">		out.writeDouble(price);</span><br><span class="line">	&#125;</span><br><span class="line"></span><br><span class="line">	<span class="meta">@Override</span></span><br><span class="line">	<span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">readFields</span><span class="params">(DataInput in)</span> <span class="keyword">throws</span> IOException &#123;</span><br><span class="line">		order_id = in.readInt();</span><br><span class="line">		price=in.readDouble();</span><br><span class="line">	&#125;</span><br><span class="line"></span><br><span class="line">	<span class="comment">// 二次排序：在自定义排序过程中，如果compareTo中的判断条件为两个即为二次排序</span></span><br><span class="line">	<span class="meta">@Override</span></span><br><span class="line">	<span class="keyword">public</span> <span class="type">int</span> <span class="title function_">compareTo</span><span class="params">(OrderBean o)</span> &#123;</span><br><span class="line"></span><br><span class="line">		<span class="type">int</span> result;</span><br><span class="line"></span><br><span class="line">		<span class="comment">// 比较结果中，-1代表排在前面，1代表排在后面</span></span><br><span class="line">		<span class="comment">// order_id正序排列</span></span><br><span class="line">		<span class="keyword">if</span> (order_id &gt; o.getOrder_id()) &#123;</span><br><span class="line">			result = <span class="number">1</span>;</span><br><span class="line">		&#125; <span class="keyword">else</span> <span class="keyword">if</span> (order_id &lt; o.getOrder_id()) &#123;</span><br><span class="line">			result = -<span class="number">1</span>;</span><br><span class="line">		&#125; <span class="keyword">else</span> &#123;</span><br><span class="line"></span><br><span class="line">			<span class="comment">// 价格倒序排列</span></span><br><span class="line">			<span class="keyword">if</span> (price &gt; o.getPrice()) &#123;</span><br><span class="line">				result = -<span class="number">1</span>;</span><br><span class="line">			&#125; <span class="keyword">else</span> <span class="keyword">if</span> (price &lt; o.getPrice()) &#123;</span><br><span class="line">				result = <span class="number">1</span>;</span><br><span class="line">			&#125; <span class="keyword">else</span> &#123;</span><br><span class="line">				result = <span class="number">0</span>;</span><br><span class="line">			&#125;</span><br><span class="line">			</span><br><span class="line"><span class="comment">//			result = price &gt;o.getPrice()?-1:1;</span></span><br><span class="line">		&#125;</span><br><span class="line"></span><br><span class="line">		<span class="keyword">return</span> result;</span><br><span class="line">	&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>（2）编写OrderMapper类</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> java.io.IOException;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.io.LongWritable;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.io.NullWritable;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.io.Text;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.mapreduce.Mapper;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">OrderMapper</span> <span class="keyword">extends</span> <span class="title class_">Mapper</span>&lt;LongWritable, Text, OrderBean, NullWritable&gt; &#123;</span><br><span class="line">	</span><br><span class="line">	<span class="type">OrderBean</span> <span class="variable">k</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">OrderBean</span>();</span><br><span class="line"></span><br><span class="line">	<span class="meta">@Override</span></span><br><span class="line">	<span class="keyword">protected</span> <span class="keyword">void</span> <span class="title function_">map</span><span class="params">(LongWritable key, Text value, Context context)</span> <span class="keyword">throws</span> IOException, InterruptedException &#123;</span><br><span class="line"></span><br><span class="line">		<span class="comment">// 1 获取一行</span></span><br><span class="line">		<span class="type">String</span> <span class="variable">line</span> <span class="operator">=</span> value.toString();</span><br><span class="line"></span><br><span class="line">		<span class="comment">// 2 截取</span></span><br><span class="line">		String[] fields = line.split(<span class="string">&quot;\t&quot;</span>);</span><br><span class="line"></span><br><span class="line">		<span class="comment">// 3 封装对象</span></span><br><span class="line">		k.setOrder_id(Integer.parseInt(fields[<span class="number">0</span>]));</span><br><span class="line">		k.setPrice(Double.parseDouble(fields[<span class="number">2</span>]));</span><br><span class="line"></span><br><span class="line">		<span class="comment">// 4 写出，注意NullWritable加上了get()方法</span></span><br><span class="line">		context.write(k, NullWritable.get());</span><br><span class="line">	&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>（3）编写OrderSortGroupingComparator类</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> org.apache.hadoop.io.WritableComparable;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.io.WritableComparator;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">OrderSortGroupingComparator</span> <span class="keyword">extends</span> <span class="title class_">WritableComparator</span>&#123;</span><br><span class="line">	<span class="keyword">protected</span> <span class="title function_">OrderSortGroupingComparator</span><span class="params">()</span> &#123;</span><br><span class="line">		<span class="comment">// 第二个参数true一定不能省，否则会报错</span></span><br><span class="line">		<span class="built_in">super</span>(OrderBean.class,<span class="literal">true</span>);</span><br><span class="line">	&#125;</span><br><span class="line">	</span><br><span class="line">	<span class="meta">@Override</span></span><br><span class="line">	<span class="keyword">public</span> <span class="type">int</span> <span class="title function_">compare</span><span class="params">(WritableComparable a, WritableComparable b)</span> &#123;</span><br><span class="line"></span><br><span class="line">		<span class="comment">// 只要order_id相同就认为是相同的key</span></span><br><span class="line"></span><br><span class="line">		<span class="type">OrderBean</span> <span class="variable">aBean</span> <span class="operator">=</span> (OrderBean) a;</span><br><span class="line">		<span class="type">OrderBean</span> <span class="variable">bBean</span> <span class="operator">=</span> (OrderBean) b;</span><br><span class="line"></span><br><span class="line">		<span class="type">int</span> result;</span><br><span class="line"></span><br><span class="line">		<span class="keyword">if</span> (aBean.getOrder_id() &gt; bBean.getOrder_id()) &#123;</span><br><span class="line">			result = <span class="number">1</span>;</span><br><span class="line">		&#125; <span class="keyword">else</span> <span class="keyword">if</span> (aBean.getOrder_id() &lt; bBean.getOrder_id()) &#123;</span><br><span class="line">			result = -<span class="number">1</span>;</span><br><span class="line">		&#125; <span class="keyword">else</span> &#123;</span><br><span class="line">			result = <span class="number">0</span>;</span><br><span class="line">		&#125;</span><br><span class="line"></span><br><span class="line">		<span class="keyword">return</span> result;</span><br><span class="line">	&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>（4）编写OrderReducer类</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> java.io.IOException;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.io.NullWritable;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.mapreduce.Reducer;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">OrderReducer</span> <span class="keyword">extends</span> <span class="title class_">Reducer</span>&lt;OrderBean, NullWritable, OrderBean, NullWritable&gt;&#123;</span><br><span class="line">	<span class="meta">@Override</span></span><br><span class="line">	<span class="keyword">protected</span> <span class="keyword">void</span> <span class="title function_">reduce</span><span class="params">(OrderBean key, Iterable&lt;NullWritable&gt; values, Context context)</span> <span class="keyword">throws</span> IOException, InterruptedException &#123;</span><br><span class="line">		context.write(key, NullWritable.get());</span><br><span class="line">	&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>（5）编写OrderDriver类</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> java.io.IOException;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.conf.Configuration;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.fs.Path;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.io.NullWritable;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.mapreduce.Job;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.mapreduce.lib.input.FileInputFormat;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.mapreduce.lib.output.FileOutputFormat;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">OrderDriver</span> &#123;</span><br><span class="line">	<span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title function_">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> Exception, IOException &#123;</span><br><span class="line"></span><br><span class="line">		<span class="comment">// 输入输出路径需要根据自己电脑上实际的输入输出路径设置</span></span><br><span class="line">		args = <span class="keyword">new</span> <span class="title class_">String</span>[] &#123; <span class="string">&quot;d:/input/inputOrder&quot;</span>, <span class="string">&quot;d:/outputOrder&quot;</span> &#125;;</span><br><span class="line"></span><br><span class="line">		<span class="comment">// 1 获取配置信息</span></span><br><span class="line">		<span class="type">Configuration</span> <span class="variable">conf</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">Configuration</span>();</span><br><span class="line">		<span class="type">Job</span> <span class="variable">job</span> <span class="operator">=</span> Job.getInstance(conf);</span><br><span class="line"></span><br><span class="line">		<span class="comment">// 2 设置jar包加载路径</span></span><br><span class="line">		job.setJarByClass(OrderDriver.class);</span><br><span class="line"></span><br><span class="line">		<span class="comment">// 3 加载map/reduce类</span></span><br><span class="line">		job.setMapperClass(OrderMapper.class);</span><br><span class="line">		job.setReducerClass(OrderReducer.class);</span><br><span class="line">		</span><br><span class="line">		<span class="comment">// 8 设置reduce端的分组，负责比较相同key值，然后对进入ReduceTask的键值对进行分组，否则OrderSortGroupingComparator类无法发挥作用，直接把每个键值对单独分为一组</span></span><br><span class="line">		job.setGroupingComparatorClass(OrderSortGroupingComparator.class);</span><br><span class="line"></span><br><span class="line">		<span class="comment">// 4 设置map输出数据key和value类型</span></span><br><span class="line">		job.setMapOutputKeyClass(OrderBean.class);</span><br><span class="line">		job.setMapOutputValueClass(NullWritable.class);</span><br><span class="line"></span><br><span class="line">		<span class="comment">// 5 设置最终输出数据的key和value类型</span></span><br><span class="line">		job.setOutputKeyClass(OrderBean.class);</span><br><span class="line">		job.setOutputValueClass(NullWritable.class);</span><br><span class="line"></span><br><span class="line">		<span class="comment">// 6 设置输入数据和输出数据路径</span></span><br><span class="line">		FileInputFormat.setInputPaths(job, <span class="keyword">new</span> <span class="title class_">Path</span>(args[<span class="number">0</span>]));</span><br><span class="line">		FileOutputFormat.setOutputPath(job, <span class="keyword">new</span> <span class="title class_">Path</span>(args[<span class="number">1</span>]));</span><br><span class="line"></span><br><span class="line">		<span class="comment">// 7 提交</span></span><br><span class="line">		<span class="type">boolean</span> <span class="variable">result</span> <span class="operator">=</span> job.waitForCompletion(<span class="literal">true</span>);</span><br><span class="line">		System.exit(result ? <span class="number">0</span> : <span class="number">1</span>);</span><br><span class="line">	&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p><strong>Tip：</strong></p>
<ul>
<li><strong>如果要求获取每个订单号价格前N位的商品，在Reduce方法中，设置同一组内循环输出N次value值即可。</strong></li>
<li><strong>Reduce阶段对Map阶段输出的键值对进行分组时，默认Map阶段已经排序，仅通过GroupingComparator类从上往下寻找不同组的键值对，然后把不同组键值对以上的部分自动分为一组。</strong></li>
</ul>
<center>——————未完待续，以下内容后续补充——————</center>

<h2 id="3-4-MapTask工作机制"><a href="#3-4-MapTask工作机制" class="headerlink" title="3.4 MapTask工作机制"></a>3.4 MapTask工作机制</h2><h2 id="3-5-ReduceTak工作机制"><a href="#3-5-ReduceTak工作机制" class="headerlink" title="3.5 ReduceTak工作机制"></a>3.5 ReduceTak工作机制</h2><h2 id="3-6-OutputFormat数据输出"><a href="#3-6-OutputFormat数据输出" class="headerlink" title="3.6 OutputFormat数据输出"></a>3.6 OutputFormat数据输出</h2><h3 id="3-6-1-OutputFormat接口实现类"><a href="#3-6-1-OutputFormat接口实现类" class="headerlink" title="3.6.1 OutputFormat接口实现类"></a>3.6.1 OutputFormat接口实现类</h3><h3 id="3-6-2-自定义OutputFormat"><a href="#3-6-2-自定义OutputFormat" class="headerlink" title="3.6.2 自定义OutputFormat"></a>3.6.2 自定义OutputFormat</h3><h3 id="3-6-3-自定义OutputFormat案例实操"><a href="#3-6-3-自定义OutputFormat案例实操" class="headerlink" title="3.6.3 自定义OutputFormat案例实操"></a>3.6.3 自定义OutputFormat案例实操</h3><h2 id="3-7-Join多种应用"><a href="#3-7-Join多种应用" class="headerlink" title="3.7 Join多种应用"></a>3.7 Join多种应用</h2><h3 id="3-7-1-Reduce-Join"><a href="#3-7-1-Reduce-Join" class="headerlink" title="3.7.1 Reduce Join"></a>3.7.1 Reduce Join</h3><h3 id="3-7-2-Reduce-Join案例实操"><a href="#3-7-2-Reduce-Join案例实操" class="headerlink" title="3.7.2 Reduce Join案例实操"></a>3.7.2 Reduce Join案例实操</h3><h3 id="3-7-3-Map-Join"><a href="#3-7-3-Map-Join" class="headerlink" title="3.7.3 Map Join"></a>3.7.3 Map Join</h3><h3 id="3-7-4-Map-Join案例实操"><a href="#3-7-4-Map-Join案例实操" class="headerlink" title="3.7.4 Map Join案例实操"></a>3.7.4 Map Join案例实操</h3><p>······</p>
<p><strong>PS</strong>：视频教程查看<a target="_blank" rel="noopener" href="http://www.atguigu.com/download_detail.shtml?v=52">尚硅谷-Hadoop视频教程</a>。</p>

                
            </div>
            <hr/>

            

    <div class="reprint" id="reprint-statement">
        
            <div class="reprint__author">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-user">
                        Author:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="/about" rel="external nofollow noreferrer">fdChen</a>
                </span>
            </div>
            <div class="reprint__type">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-link">
                        Link:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="http://blog.fdchen.host/2022/fen-bu-shi-ji-suan-kuang-jia-mapreduce-ge-shi-diao-zheng-zhi-1.7/">http://blog.fdchen.host/2022/fen-bu-shi-ji-suan-kuang-jia-mapreduce-ge-shi-diao-zheng-zhi-1.7/</a>
                </span>
            </div>
            <div class="reprint__notice">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-copyright">
                        Reprint policy:
                    </i>
                </span>
                <span class="reprint-info">
                    All articles in this blog are used except for special statements
                    <a href="https://creativecommons.org/licenses/by/4.0/deed.zh" rel="external nofollow noreferrer" target="_blank">CC BY 4.0</a>
                    reprint policy. If reproduced, please indicate source
                    <a href="/about" target="_blank">fdChen</a>
                    !
                </span>
            </div>
        
    </div>

    <script async defer>
      document.addEventListener("copy", function (e) {
        let toastHTML = '<span>Copied successfully, please follow the reprint policy of this article</span><button class="btn-flat toast-action" onclick="navToReprintStatement()" style="font-size: smaller">more</a>';
        M.toast({html: toastHTML})
      });

      function navToReprintStatement() {
        $("html, body").animate({scrollTop: $("#reprint-statement").offset().top - 80}, 800);
      }
    </script>



            <div class="tag_share" style="display: block;">
                <div class="post-meta__tag-list" style="display: inline-block;">
                    
                        <div class="article-tag">
                            
                                <a href="/tags/Hadoop/">
                                    <span class="chip bg-color">Hadoop</span>
                                </a>
                            
                                <a href="/tags/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/">
                                    <span class="chip bg-color">学习笔记</span>
                                </a>
                            
                                <a href="/tags/%E6%95%99%E7%A8%8B/">
                                    <span class="chip bg-color">教程</span>
                                </a>
                            
                                <a href="/tags/MapReduce/">
                                    <span class="chip bg-color">MapReduce</span>
                                </a>
                            
                        </div>
                    
                </div>
                <div class="post_share" style="zoom: 80%; width: fit-content; display: inline-block; float: right; margin: -0.15rem 0;">
                    <link rel="stylesheet" type="text/css" href="/libs/share/css/share.min.css">
<div id="article-share">

    
    <div class="social-share" data-sites="twitter,facebook,google,qq,qzone,wechat,weibo,douban,linkedin" data-wechat-qrcode-helper="<p>微信扫一扫即可分享！</p>"></div>
    <script src="/libs/share/js/social-share.min.js"></script>
    

    

</div>

                </div>
            </div>
            
                <style>
    #reward {
        margin: 40px 0;
        text-align: center;
    }

    #reward .reward-link {
        font-size: 1.4rem;
        line-height: 38px;
    }

    #reward .btn-floating:hover {
        box-shadow: 0 6px 12px rgba(0, 0, 0, 0.2), 0 5px 15px rgba(0, 0, 0, 0.2);
    }

    #rewardModal {
        width: 320px;
        height: 350px;
    }

    #rewardModal .reward-title {
        margin: 15px auto;
        padding-bottom: 5px;
    }

    #rewardModal .modal-content {
        padding: 10px;
    }

    #rewardModal .close {
        position: absolute;
        right: 15px;
        top: 15px;
        color: rgba(0, 0, 0, 0.5);
        font-size: 1.3rem;
        line-height: 20px;
        cursor: pointer;
    }

    #rewardModal .close:hover {
        color: #ef5350;
        transform: scale(1.3);
        -moz-transform:scale(1.3);
        -webkit-transform:scale(1.3);
        -o-transform:scale(1.3);
    }

    #rewardModal .reward-tabs {
        margin: 0 auto;
        width: 210px;
    }

    .reward-tabs .tabs {
        height: 38px;
        margin: 10px auto;
        padding-left: 0;
    }

    .reward-content ul {
        padding-left: 0 !important;
    }

    .reward-tabs .tabs .tab {
        height: 38px;
        line-height: 38px;
    }

    .reward-tabs .tab a {
        color: #fff;
        background-color: #ccc;
    }

    .reward-tabs .tab a:hover {
        background-color: #ccc;
        color: #fff;
    }

    .reward-tabs .wechat-tab .active {
        color: #fff !important;
        background-color: #22AB38 !important;
    }

    .reward-tabs .alipay-tab .active {
        color: #fff !important;
        background-color: #019FE8 !important;
    }

    .reward-tabs .reward-img {
        width: 210px;
        height: 210px;
    }
</style>

<div id="reward">
    <a href="#rewardModal" class="reward-link modal-trigger btn-floating btn-medium waves-effect waves-light red">赏</a>

    <!-- Modal Structure -->
    <div id="rewardModal" class="modal">
        <div class="modal-content">
            <a class="close modal-close"><i class="fas fa-times"></i></a>
            <h4 class="reward-title">你的赏识是我前进的动力</h4>
            <div class="reward-content">
                <div class="reward-tabs">
                    <ul class="tabs row">
                        <li class="tab col s6 alipay-tab waves-effect waves-light"><a href="#alipay">支付宝</a></li>
                        <li class="tab col s6 wechat-tab waves-effect waves-light"><a href="#wechat">微 信</a></li>
                    </ul>
                    <div id="alipay">
                        <img src="/medias/reward/alipay.jpg" class="reward-img" alt="支付宝打赏二维码">
                    </div>
                    <div id="wechat">
                        <img src="/medias/reward/wechat.png" class="reward-img" alt="微信打赏二维码">
                    </div>
                </div>
            </div>
        </div>
    </div>
</div>

<script>
    $(function () {
        $('.tabs').tabs();
    });
</script>

            
        </div>
    </div>

    

    

    

    

    

    

    

    

    

    

<article id="prenext-posts" class="prev-next articles">
    <div class="row article-row">
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge left-badge text-color">
                <i class="fas fa-chevron-left"></i>&nbsp;Previous</div>
            <div class="card">
                <a href="/2022/ke-yan-ru-men-tips/">
                    <div class="card-image">
                        
                        
                        <img src="/medias/featureimages/0.jpg" class="responsive-img" alt="">
                        
                        <span class="card-title"></span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            
                        
                    </div>
                    <div class="publish-info">
                        <span class="publish-date">
                            <i class="far fa-clock fa-fw icon-date"></i>2022-03-16
                        </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-user fa-fw"></i>
                            fdChen
                            
                        </span>
                    </div>
                </div>
                
            </div>
        </div>
        
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge right-badge text-color">
                Next&nbsp;<i class="fas fa-chevron-right"></i>
            </div>
            <div class="card">
                <a href="/2022/fen-bu-shi-wen-jian-xi-tong-hdfs/">
                    <div class="card-image">
                        
                        
                        <img src="/medias/featureimages/2.jpg" class="responsive-img" alt="分布式文件系统HDFS">
                        
                        <span class="card-title">分布式文件系统HDFS</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            1 HDFS概述1.1 HDFS产生背景及定义1.1.1 HDFS产生背景随着数据量越来越大，在一个操作系统存不下所有的数据，那么就分配到更多的操作系统管理的磁盘中，但是不方便管理和维护，迫切需要一种系统来管理多台机器上的文件，这就是分布式
                        
                    </div>
                    <div class="publish-info">
                            <span class="publish-date">
                                <i class="far fa-clock fa-fw icon-date"></i>2022-03-16
                            </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90/" class="post-category">
                                    大数据分析
                                </a>
                            
                            <a href="/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90/Hadoop%E5%B7%A5%E5%85%B7%E4%BD%BF%E7%94%A8%E6%95%99%E7%A8%8B/" class="post-category">
                                    Hadoop工具使用教程
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/tags/Hadoop/">
                        <span class="chip bg-color">Hadoop</span>
                    </a>
                    
                    <a href="/tags/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/">
                        <span class="chip bg-color">学习笔记</span>
                    </a>
                    
                    <a href="/tags/%E6%95%99%E7%A8%8B/">
                        <span class="chip bg-color">教程</span>
                    </a>
                    
                    <a href="/tags/HDFS/">
                        <span class="chip bg-color">HDFS</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
    </div>
</article>

</div>


<script>
    $('#articleContent').on('copy', function (e) {
        // IE8 or earlier browser is 'undefined'
        if (typeof window.getSelection === 'undefined') return;

        var selection = window.getSelection();
        // if the selection is short let's not annoy our users.
        if (('' + selection).length < Number.parseInt('120')) {
            return;
        }

        // create a div outside of the visible area and fill it with the selected text.
        var bodyElement = document.getElementsByTagName('body')[0];
        var newdiv = document.createElement('div');
        newdiv.style.position = 'absolute';
        newdiv.style.left = '-99999px';
        bodyElement.appendChild(newdiv);
        newdiv.appendChild(selection.getRangeAt(0).cloneContents());

        // we need a <pre> tag workaround.
        // otherwise the text inside "pre" loses all the line breaks!
        if (selection.getRangeAt(0).commonAncestorContainer.nodeName === 'PRE' || selection.getRangeAt(0).commonAncestorContainer.nodeName === 'CODE') {
            newdiv.innerHTML = "<pre>" + newdiv.innerHTML + "</pre>";
        }

        var url = document.location.href;
        newdiv.innerHTML += '<br />'
            + 'From: fdChen的掉发收集箱<br />'
            + 'Author: fdChen<br />'
            + 'Link: <a href="' + url + '">' + url + '</a><br />'
            + '本文章著作权归作者所有，任何形式的转载都请注明出处。';

        selection.selectAllChildren(newdiv);
        window.setTimeout(function () {bodyElement.removeChild(newdiv);}, 200);
    });
</script>


<!-- 代码块功能依赖 -->
<script type="text/javascript" src="/libs/codeBlock/codeBlockFuction.js"></script>

<!-- 代码语言 -->

<script type="text/javascript" src="/libs/codeBlock/codeLang.js"></script>


<!-- 代码块复制 -->

<script type="text/javascript" src="/libs/codeBlock/codeCopy.js"></script>


<!-- 代码块收缩 -->

<script type="text/javascript" src="/libs/codeBlock/codeShrink.js"></script>


    </div>
    <div id="toc-aside" class="expanded col l3 hide-on-med-and-down">
        <div class="toc-widget card" style="background-color: white;">
            <div class="toc-title"><i class="far fa-list-alt"></i>&nbsp;&nbsp;TOC</div>
            <div id="toc-content"></div>
        </div>
    </div>
</div>

<!-- TOC 悬浮按钮. -->

<div id="floating-toc-btn" class="hide-on-med-and-down">
    <a class="btn-floating btn-large bg-color">
        <i class="fas fa-list-ul"></i>
    </a>
</div>


<script src="/libs/tocbot/tocbot.min.js"></script>
<script>
    $(function () {
        tocbot.init({
            tocSelector: '#toc-content',
            contentSelector: '#articleContent',
            headingsOffset: -($(window).height() * 0.4 - 45),
            collapseDepth: Number('0'),
            headingSelector: 'h2, h3, h4'
        });

        // modify the toc link href to support Chinese.
        let i = 0;
        let tocHeading = 'toc-heading-';
        $('#toc-content a').each(function () {
            $(this).attr('href', '#' + tocHeading + (++i));
        });

        // modify the heading title id to support Chinese.
        i = 0;
        $('#articleContent').children('h2, h3, h4').each(function () {
            $(this).attr('id', tocHeading + (++i));
        });

        // Set scroll toc fixed.
        let tocHeight = parseInt($(window).height() * 0.4 - 64);
        let $tocWidget = $('.toc-widget');
        $(window).scroll(function () {
            let scroll = $(window).scrollTop();
            /* add post toc fixed. */
            if (scroll > tocHeight) {
                $tocWidget.addClass('toc-fixed');
            } else {
                $tocWidget.removeClass('toc-fixed');
            }
        });

        
        /* 修复文章卡片 div 的宽度. */
        let fixPostCardWidth = function (srcId, targetId) {
            let srcDiv = $('#' + srcId);
            if (srcDiv.length === 0) {
                return;
            }

            let w = srcDiv.width();
            if (w >= 450) {
                w = w + 21;
            } else if (w >= 350 && w < 450) {
                w = w + 18;
            } else if (w >= 300 && w < 350) {
                w = w + 16;
            } else {
                w = w + 14;
            }
            $('#' + targetId).width(w);
        };

        // 切换TOC目录展开收缩的相关操作.
        const expandedClass = 'expanded';
        let $tocAside = $('#toc-aside');
        let $mainContent = $('#main-content');
        $('#floating-toc-btn .btn-floating').click(function () {
            if ($tocAside.hasClass(expandedClass)) {
                $tocAside.removeClass(expandedClass).hide();
                $mainContent.removeClass('l9');
            } else {
                $tocAside.addClass(expandedClass).show();
                $mainContent.addClass('l9');
            }
            fixPostCardWidth('artDetail', 'prenext-posts');
        });
        
    });
</script>

    

</main>




    <footer class="page-footer bg-color">
    

    <div class="container row center-align"
         style="margin-bottom: 0px !important;">
        <div class="col s12 m8 l8 copy-right">
            Copyright&nbsp;&copy;
            
                <span id="year">2022</span>
            
            <a href="/about" target="_blank">fdChen</a>
            |&nbsp;Powered by&nbsp;<a href="https://hexo.io/" target="_blank">Hexo</a>
            |&nbsp;Theme&nbsp;<a href="https://github.com/blinkfox/hexo-theme-matery" target="_blank">Matery</a>
            <br>
            
                &nbsp;<i class="fas fa-chart-area"></i>&nbsp;Total Words:&nbsp;<span
                        class="white-color">132.6k</span>
            
            
            
                
            
            
                <span id="busuanzi_container_site_pv">
                &nbsp;|&nbsp;<i class="far fa-eye"></i>&nbsp;Total visits:&nbsp;
                    <span id="busuanzi_value_site_pv" class="white-color"></span>
            </span>
            
            
                <span id="busuanzi_container_site_uv">
                &nbsp;|&nbsp;<i class="fas fa-users"></i>&nbsp;Total visitors:&nbsp;
                    <span id="busuanzi_value_site_uv" class="white-color"></span>
            </span>
            
            <br>

            <!-- 运行天数提醒. -->
            
            <br>
            
                <span id="icp"><img src="/medias/icp.png"
                                    style="vertical-align: text-bottom;"/>
                <a href="/beian.miit.gov.cn" target="_blank">湘ICP备20016057号</a>
            </span>
            
        </div>
        <div class="col s12 m4 l4 social-link social-statis">
    <a href="https://github.com/CCSemicircle" class="tooltipped" target="_blank" data-tooltip="访问我的GitHub" data-position="top" data-delay="50">
        <i class="fab fa-github"></i>
    </a>



    <a href="mailto:fangd.chen@gmail.com" class="tooltipped" target="_blank" data-tooltip="邮件联系我" data-position="top" data-delay="50">
        <i class="fas fa-envelope-open"></i>
    </a>







    <a href="tencent://AddContact/?fromId=50&fromSubId=1&subcmd=all&uin=2914756796" class="tooltipped" target="_blank" data-tooltip="QQ联系我: 2914756796" data-position="top" data-delay="50">
        <i class="fab fa-qq"></i>
    </a>





    <a href="https://www.zhihu.com/people/semi-circle-42/posts" class="tooltipped" target="_blank" data-tooltip="关注我的知乎" data-position="top" data-delay="50">
        <i class="fab fa-zhihu1">知</i>
    </a>



</div>
    </div>
</footer>

<div class="progress-bar"></div>


    <!-- 搜索遮罩框 -->
<div id="searchModal" class="modal">
    <div class="modal-content">
        <div class="search-header">
            <span class="title"><i class="fas fa-search"></i>&nbsp;&nbsp;Search</span>
            <input type="search" id="searchInput" name="s" placeholder="Please enter a search keyword"
                   class="search-input">
        </div>
        <div id="searchResult"></div>
    </div>
</div>

<script type="text/javascript">
$(function () {
    var searchFunc = function (path, search_id, content_id) {
        'use strict';
        $.ajax({
            url: path,
            dataType: "xml",
            success: function (xmlResponse) {
                // get the contents from search data
                var datas = $("entry", xmlResponse).map(function () {
                    return {
                        title: $("title", this).text(),
                        content: $("content", this).text(),
                        url: $("url", this).text()
                    };
                }).get();
                var $input = document.getElementById(search_id);
                var $resultContent = document.getElementById(content_id);
                $input.addEventListener('input', function () {
                    var str = '<ul class=\"search-result-list\">';
                    var keywords = this.value.trim().toLowerCase().split(/[\s\-]+/);
                    $resultContent.innerHTML = "";
                    if (this.value.trim().length <= 0) {
                        return;
                    }
                    // perform local searching
                    datas.forEach(function (data) {
                        var isMatch = true;
                        var data_title = data.title.trim().toLowerCase();
                        var data_content = data.content.trim().replace(/<[^>]+>/g, "").toLowerCase();
                        var data_url = data.url;
                        data_url = data_url.indexOf('/') === 0 ? data.url : '/' + data_url;
                        var index_title = -1;
                        var index_content = -1;
                        var first_occur = -1;
                        // only match artiles with not empty titles and contents
                        if (data_title !== '' && data_content !== '') {
                            keywords.forEach(function (keyword, i) {
                                index_title = data_title.indexOf(keyword);
                                index_content = data_content.indexOf(keyword);
                                if (index_title < 0 && index_content < 0) {
                                    isMatch = false;
                                } else {
                                    if (index_content < 0) {
                                        index_content = 0;
                                    }
                                    if (i === 0) {
                                        first_occur = index_content;
                                    }
                                }
                            });
                        }
                        // show search results
                        if (isMatch) {
                            str += "<li><a href='" + data_url + "' class='search-result-title'>" + data_title + "</a>";
                            var content = data.content.trim().replace(/<[^>]+>/g, "");
                            if (first_occur >= 0) {
                                // cut out 100 characters
                                var start = first_occur - 20;
                                var end = first_occur + 80;
                                if (start < 0) {
                                    start = 0;
                                }
                                if (start === 0) {
                                    end = 100;
                                }
                                if (end > content.length) {
                                    end = content.length;
                                }
                                var match_content = content.substr(start, end);
                                // highlight all keywords
                                keywords.forEach(function (keyword) {
                                    var regS = new RegExp(keyword, "gi");
                                    match_content = match_content.replace(regS, "<em class=\"search-keyword\">" + keyword + "</em>");
                                });

                                str += "<p class=\"search-result\">" + match_content + "...</p>"
                            }
                            str += "</li>";
                        }
                    });
                    str += "</ul>";
                    $resultContent.innerHTML = str;
                });
            }
        });
    };

    searchFunc('/search.xml', 'searchInput', 'searchResult');
});
</script>

    <!-- 回到顶部按钮 -->
<div id="backTop" class="top-scroll">
    <a class="btn-floating btn-large waves-effect waves-light" href="#!">
        <i class="fas fa-arrow-up"></i>
    </a>
</div>


    <script src="/libs/materialize/materialize.min.js"></script>
    <script src="/libs/masonry/masonry.pkgd.min.js"></script>
    <script src="/libs/aos/aos.js"></script>
    <script src="/libs/scrollprogress/scrollProgress.min.js"></script>
    <script src="/libs/lightGallery/js/lightgallery-all.min.js"></script>
    <script src="/js/matery.js"></script>

    

    
        
        <script type="text/javascript">
            // 只在桌面版网页启用特效
            var windowWidth = $(window).width();
            if (windowWidth > 768) {
                document.write('<script type="text/javascript" src="/libs/others/sakura.js"><\/script>');
            }
        </script>
    

    <!-- 雪花特效 -->
    

    <!-- 鼠标星星特效 -->
    

     
        <script src="https://ssl.captcha.qq.com/TCaptcha.js"></script>
        <script src="/libs/others/TencentCaptcha.js"></script>
        <button id="TencentCaptcha" data-appid="xxxxxxxxxx" data-cbfn="callback" type="button" hidden></button>
    

    <!-- Baidu Analytics -->

    <!-- Baidu Push -->

<script>
    (function () {
        var bp = document.createElement('script');
        var curProtocol = window.location.protocol.split(':')[0];
        if (curProtocol === 'https') {
            bp.src = 'https://zz.bdstatic.com/linksubmit/push.js';
        } else {
            bp.src = 'http://push.zhanzhang.baidu.com/push.js';
        }
        var s = document.getElementsByTagName("script")[0];
        s.parentNode.insertBefore(bp, s);
    })();
</script>

    
    <script src="/libs/others/clicklove.js" async="async"></script>
    
    
    <script async src="/libs/others/busuanzi.pure.mini.js"></script>
    

    

    

    <!--腾讯兔小巢-->
    
    

    

    

    
    <script src="/libs/instantpage/instantpage.js" type="module"></script>
    

</body>

</html>
